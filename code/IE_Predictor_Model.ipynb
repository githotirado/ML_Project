{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9cffe5-5e75-4d73-a671-de8740200892",
   "metadata": {},
   "source": [
    "# Trait Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed1213-53c0-40df-bfa4-6664880db7b0",
   "metadata": {},
   "source": [
    "Project objective was to develop the machine learning application that would predict the personality trait of a person as Introvert/Extrovert/Ambivert based on 91 personality questions. Our ML algorithm is trained based on survey with the same set of personality questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933f65c-860b-4169-b26d-c07a0b513911",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2586bf-b411-4666-baf8-4fd9b3912e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from config import driver, username, password, host, port, database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822f5d1-643a-418d-a9ba-b3a2c98e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"{driver}://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(connection_string)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9b5224-ef48-46d7-aa05-3a6f49d35d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QuestionsListDF = pd.read_sql_table('questionslist', connection)\n",
    "# QuestionsListDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ecc887-c5f4-4963-ba0d-6a28ebfc34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_columns = 300\n",
    "# pd.options.display.max_columns = 100\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f0ac432-28c8-4805-aa74-7ad42fbde162",
   "metadata": {
    "tags": []
   },
   "source": [
    "# About the Questionnaire Survey responses data\n",
    "\n",
    "A - The user's selected response. 1=Disagree, 2=Slightly disagree, 3=Neutral, 4=Slightly agree, 5=Agree\n",
    "I - The position of the question in the survey.\n",
    "E - The time elapsed on that question in milliseconds.\n",
    "\n",
    "gender: \"What is your gender?\"\t 1=Male 2=Female 3=Other\n",
    "engnat: Is English your native language?\"\t1=Yes 2=No\n",
    "age:\"What is your age in years?\"\n",
    "introvert_extrovert:\"Do you identify as either an introvert or extravert?\"\t1=Yes, introvert 2=Yes, extravert 3=No\n",
    "country:\tuser's network location\n",
    "dateload:\tthe time the user loaded the introduction page\n",
    "introelapse:\tthe time spent in seconds on the introduction page\n",
    "testelapse:\tthe time spent in seconds on the test questions\n",
    "surveyelapse:\tthe time spent in seconds on the final page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd389bc-557c-4ef9-be7c-79fd81102340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7188 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7188 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local csv file read\n",
    "\n",
    "QuestionnaireDF = pd.read_csv(Path('../resources/data.csv'), delimiter='\\t')\n",
    "QuestionnaireDF.rename(columns ={'country':'COUNTRY', \n",
    "                                 'dateload':'DATELOAD',\n",
    "                                 'introelapse':'INTROELAPSE',\n",
    "                                 'testelapse':'TESTELAPSE',\n",
    "                                 'surveyelapse':'SURVEYELAPSE',\n",
    "                                 'gender':'GENDER',\n",
    "                                 'engnat':'ENGNAT',\n",
    "                                 'age':'AGE',\n",
    "                                 'IE':'INTROVERT_EXTROVERT'}, inplace=True)\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035ed6e1-336b-42bc-838e-358af9beab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from AWS\n",
    "\n",
    "# QuestionnaireDF = pd.read_sql_table('questionnaire', connection)\n",
    "# QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842032-4b2a-4de8-84c3-2f76cd9134fc",
   "metadata": {},
   "source": [
    "## Preprocessing: Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758b3201-edd4-474e-b6fb-a783a64bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7163 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7163 rows x 282 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the rows that are not contributing to Classification values \"Introvert/Extrovert/Ambivert\" \n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.loc[QuestionnaireDF['INTROVERT_EXTROVERT'] != 0]\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014b0fe3-98f4-41d6-8a66-d6a9a46f84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q90I</th>\n",
       "      <th>Q90E</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>Q91I</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4648</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3884</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10409</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2345</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>6413</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  Q4A  ...  Q90A  Q90I  Q90E  \\\n",
       "0    5   51  7107    3   91  2522    1   56  6180    2  ...     3    40  4648   \n",
       "1    5   39  6354    5   13  3092    1   12  5243    5  ...     4    28  3884   \n",
       "2    3   17  5397    4   35  2747    5   40  5262    3  ...     1    87  1759   \n",
       "3    5   41  3055    2   14  3348    1   13  5141    1  ...     3    15  2345   \n",
       "4    1   76  2542    2   54  1878    1   15  5637    1  ...     5    86  6413   \n",
       "\n",
       "   Q91A  Q91I   Q91E  GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0     3    35   4609       2       1   23                    3  \n",
       "1     3     1  10409       1       2   25                    2  \n",
       "2     1    19   2691       1       2   19                    1  \n",
       "3     3    23   3697       1       1   23                    1  \n",
       "4     5    69   1662       1       1   18                    2  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only features that are considered to be important for training the model\n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.drop(columns=['COUNTRY', 'DATELOAD', 'INTROELAPSE', 'TESTELAPSE', 'SURVEYELAPSE'])\n",
    "QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a15c57e-f4b3-4fee-a586-0c76bf0a0e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     14,      15,      16,      17,      18,      19,      20,\n",
       "            21,      22,      23,      24,      25,      26,      27,\n",
       "            28,      29,      30,      31,      32,      33,      34,\n",
       "            35,      36,      37,      38,      39,      40,      41,\n",
       "            42,      43,      44,      45,      46,      47,      48,\n",
       "            49,      50,      51,      52,      53,      54,      55,\n",
       "            56,      57,      58,      59,      60,      61,      62,\n",
       "            63,      64,      65,      66,      67,      68,      69,\n",
       "            70,      71,      72,      73,      75,      77,      78,\n",
       "            79,      81,      90,     255,    1979,    1983,    1990,\n",
       "          1991,    1996,    1999,    2003, 8675309], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the data in the selected features\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4128fcc0-a29f-48fc-95d7-87e417e9b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for cleaning age feature. Drop rows with age above max_age\n",
    "\n",
    "max_age = 100\n",
    "# Age: Clean up invalid rows where age is above max_age\n",
    "age_range = (QuestionnaireDF['AGE'] < max_age)\n",
    "QuestionnaireDF = QuestionnaireDF.loc[age_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b76c0a5-9a1a-486b-b342-10ea554da41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "       48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 81, 90],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF values after the age clean up\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e89df7-0229-4166-8564-f653b9880dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Selecting only the response columns from the dataframe. Ignoring the columns with Question sequence and response time.\n",
    "\n",
    "ColumnsList = QuestionnaireDF.columns.to_list()\n",
    "\n",
    "surveyResponseColumnsList = []\n",
    "for column in ColumnsList:\n",
    "    if (column[0] == 'Q' and column[-1] == 'A'):\n",
    "        surveyResponseColumnsList.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f546b3-2155-4435-91ea-6374a324d4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsList = []\n",
    "# for column in ColumnsList:\n",
    "#     if (column[0] == 'Q' and column[-1] == 'E'):\n",
    "#         elapsedTimeColumnsList.append(column)\n",
    "        \n",
    "# elapsedTimeColumnsList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e432a4e-0aa9-4b0e-8dbe-6ea776e5df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsDF = QuestionnaireDF[['Q1E', 'Q2E', 'Q3E', 'Q4E', 'Q5E']]\n",
    "# elapsedTimeColumnsDF = QuestionnaireDF[elapsedTimeColumnsList]\n",
    "# elapsedTimeColumnsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7a3c6b-37b5-4359-8589-9f8f038677e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 Minute = 60 Seconds = 60,000 Milliseconds\n",
    "# Identify all rows that have atleast one response time more than 1 minute\n",
    "\n",
    "# elapsedTimeColumnsDF['Q1E'].loc[lambda x : x > 60000]\n",
    "# outliersDF = elapsedTimeColumnsDF[elapsedTimeColumnsDF.gt(60000).any(axis=1)]\n",
    "# outliersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276bd704-f25e-4a76-adcc-f1461996cbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outliersinSecondsDF=outliersDF/1000\n",
    "# outliersinSecondsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98be2f21-1c42-4c42-b8fa-0e00803ccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     3     2   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     2     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     3     1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     3     5   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     5   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     4     5   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     4     4   \n",
       "\n",
       "      Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0        1     4     2     5     4     3     3                    3  \n",
       "1        2     1     3     4     4     4     3                    2  \n",
       "2        5     4     5     3     2     1     1                    1  \n",
       "3        5     3     5     4     4     3     3                    1  \n",
       "4        1     3     1     2     5     5     5                    2  \n",
       "...    ...   ...   ...   ...   ...   ...   ...                  ...  \n",
       "7183     3     4     3     4     2     5     4                    1  \n",
       "7184     4     5     4     3     1     3     2                    1  \n",
       "7185     5     4     5     3     1     1     1                    1  \n",
       "7186     1     4     1     1     4     5     2                    1  \n",
       "7187     2     4     3     5     4     4     4                    1  \n",
       "\n",
       "[7153 rows x 92 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Cleansed DF for Machine Learning. Since the data is already numeric, there is no need to convert the categorical data to numeric.\n",
    "\n",
    "CleansedDF = QuestionnaireDF[surveyResponseColumnsList].copy()\n",
    "\n",
    "#Initially we thought of using Gender, English Language and Age for Predicting the personality. But later we changed our thoughts.\n",
    "# CleansedDF['GENDER'] = QuestionnaireDF['GENDER']\n",
    "# CleansedDF['ENGNAT'] = QuestionnaireDF['ENGNAT']\n",
    "# CleansedDF['AGE'] = QuestionnaireDF['AGE']\n",
    "\n",
    "CleansedDF['INTROVERT_EXTROVERT'] = QuestionnaireDF['INTROVERT_EXTROVERT']\n",
    "\n",
    "CleansedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fcd34-1cb2-45ac-8b24-51e4b677fd8a",
   "metadata": {},
   "source": [
    "## Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a6311a-54c8-48fc-8e05-1f65e5038b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  Q85A  \\\n",
       "0    5    3    1    2    3    2    3    3    4     5  ...     3     2     1   \n",
       "1    5    5    1    5    2    2    5    2    1     3  ...     2     2     2   \n",
       "2    3    4    5    3    4    5    5    5    5     5  ...     5     5     5   \n",
       "3    5    2    1    1    5    5    5    4    4     2  ...     5     5     5   \n",
       "4    1    2    1    1    3    3    5    1    3     4  ...     3     1     1   \n",
       "\n",
       "   Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0     4     2     5     4     3     3                    3  \n",
       "1     1     3     4     4     4     3                    2  \n",
       "2     4     5     3     2     1     1                    1  \n",
       "3     3     5     4     4     3     3                    1  \n",
       "4     3     1     2     5     5     5                    2  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleansedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154f54cd-651d-46f5-b713-4d40e4be1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q82A</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q82A  Q83A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     1     3   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     1     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     2     3   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     4     3   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     3   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     5     4   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     3     4   \n",
       "\n",
       "      Q84A  Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  \n",
       "0        2     1     4     2     5     4     3     3  \n",
       "1        2     2     1     3     4     4     4     3  \n",
       "2        5     5     4     5     3     2     1     1  \n",
       "3        5     5     3     5     4     4     3     3  \n",
       "4        1     1     3     1     2     5     5     5  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7183     5     3     4     3     4     2     5     4  \n",
       "7184     5     4     5     4     3     1     3     2  \n",
       "7185     5     5     4     5     3     1     1     1  \n",
       "7186     5     1     4     1     1     4     5     2  \n",
       "7187     4     2     4     3     5     4     4     4  \n",
       "\n",
       "[7153 rows x 91 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features data for training the model\n",
    "\n",
    "X = CleansedDF.drop(columns=['INTROVERT_EXTROVERT'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8a8323-13ff-42b4-802a-51866db1382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "7183    1\n",
       "7184    1\n",
       "7185    1\n",
       "7186    1\n",
       "7187    1\n",
       "Name: INTROVERT_EXTROVERT, Length: 7153, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate classification label for training the model\n",
    "\n",
    "y = CleansedDF['INTROVERT_EXTROVERT']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246ea1e0-28dc-408f-bb53-4fe18c29e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd979bc-dd76-4593-933d-e1ffc53d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape: (4792, 91) \n",
      "X_Train Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n",
      "X_Test Shape: (2361, 91) \n",
      "X_Test Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data dimensions.\n",
    "\n",
    "print(f\"X_Train Shape: {X_train.shape} \\nX_Train Columns: {X_train.columns}\")\n",
    "print(f\"X_Test Shape: {X_test.shape} \\nX_Test Columns: {X_test.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170b7a-8226-4edf-bd2e-0b33487d8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised Learning - K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97824f2e-2386-413d-a8a6-8ce2e7388f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elbow Curve based on K-Means Algorithm shows there would be 3 clusters in the dataset. This can be understood as three classes - Introvert, Extrovert and Ambivert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4823a2-0e0d-42af-8533-540b5a208f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the best value for _k_ using the Elbow Curve\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5533b8a0-e842-41b6-9a43-ea13dfa89e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow curve to identify the best number of clusters\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'], color='#DA665D')\n",
    "plt.xticks(k)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot for k-Means Cluster Analysis')\n",
    "plt.savefig('../Images/Elbow-plot-k-Means-Cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a8cad-b2b8-464c-8bf3-ad534d4fad5c",
   "metadata": {},
   "source": [
    "## Supervised Learning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0e6bc2c-fc8b-4a7b-939d-ff6a24c9addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d028a8e-d260-42c8-92e8-2ccd01710958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "\n",
    "filename = '../saved_models/IE_Predictor_model.sav'\n",
    "pickle.dump(rf_uns_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6980e60-7dc1-4903-9b6a-559d7e3b7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics and plot the matrix\n",
    "\n",
    "y_pred = rf_uns_classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=rf_uns_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=rf_uns_classifier.classes_)\n",
    "\n",
    "ml_cmap = ListedColormap(['#DA665D', '#D7BE48','#2B62BA'])\n",
    "disp.plot(cmap = ml_cmap)\n",
    "\n",
    "plt.title('1:Introvert, 2:Extrovert, 3:Ambivert')\n",
    "plt.savefig(\"../images/ConfMatrix-Introvert-Extrovert-Ambivert.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0795f71-23ce-42ae-9f16-1577040e1708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72469\n"
     ]
    }
   ],
   "source": [
    "# True Introvert, True Entrovert, True Ambert\n",
    "# accuracy = (tp + tn) / (tp + fp + tn + fn) \n",
    "\n",
    "ti, fi1, fi2, fe1, te, fe2, fa1, fa2, ta = confusion_matrix(y_test, y_pred).ravel()\n",
    "accuracy = (ti + te +ta) / (ti + fi1 + fi2 + fe1 + te + fe2 + fa1 + fa2 + ta) \n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50564db4-87cb-4df1-871d-01c63b827591",
   "metadata": {},
   "source": [
    "Since we are trying to predict more than 2 classes, the metrics cannot be calculated as average=Binary. All the 4 metrics Accuracy, Precision, Recall and F1 Score seem to good when they are calculated using \"MICRO\", \"MACRO\", \"WEIGHTED\", MICRO seems to be provide the higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04458070-d075-4e8f-be49-eb5dbd0ed8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "\n",
      "Metrics of Random Forest Classifier Model: Average=micro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.72469\n",
      "Recall = 0.72469\n",
      "F1 score = 0.72469\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the Random Forest Classifier model\n",
    "print('---------------------------------------------------------')\n",
    "print('\\nMetrics of Random Forest Classifier Model: Average=micro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4ad105-3612-4166-ba43-ce8f58ba704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=macro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.67142\n",
      "Recall = 0.61126\n",
      "F1 score = 0.63114\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=macro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5294dc5f-9d08-41e1-89f4-edc97938a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=weighted\n",
      "-----------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.70263\n",
      "Recall = 0.72469\n",
      "F1 score = 0.70506\n",
      "-----------------------------------------------------------\n",
      "Classification Report\n",
      "-----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=weighted')\n",
    "print('-----------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('-----------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03271e44-9357-4dea-aa01-48475e98cdc8",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ffd950-d382-4c4e-b564-fbfceebb2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baf1db-5a4f-4a4a-8546-d6e65a3ce893",
   "metadata": {},
   "source": [
    "## Random Forest on Scaled data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c2f378f-1f7b-443c-8088-107cae5c922e",
   "metadata": {},
   "source": [
    "We can see that there is no impact of scaling on the accuracy score in case of Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5897da-2990-41e8-8f7f-00730d1572be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_s_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train_scaled, y_train)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dc684-14ed-4e8c-903f-8f9567605f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827c914-cb50-4144-846f-8714c8053805",
   "metadata": {},
   "source": [
    "Logistic Regression has better performance over Random Forest classifier. Scaled data has little better accuracy over the Unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfb0d6cb-66b1-4f52-a3db-e2bf2793c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7765025041736227\n",
      "Testing Data Score: 0.7259635747564591\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_uns_classifier = LogisticRegression(random_state=1)\n",
    "lr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3097f58-d739-46d9-b218-dedc2888021a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7773372287145242\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_s_classifier = LogisticRegression(random_state=1)\n",
    "lr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb867c79-6066-48da-92da-935b0dccaba1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f935baf-8c8c-464f-b3cd-e125d4422678",
   "metadata": {},
   "source": [
    "Definitely Linear Regression has very low accracy and would definitely not be considered for any predictions in this app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f56d6d06-d148-44e6-98d1-7b8e3cf822a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.29771414306965005\n",
      "Testing Data Score: 0.23095512862618128\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the unscaled data and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_uns_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b160811-ce66-4561-a2ac-fe1ab526823e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: -0.18858285304377498\n",
      "Testing Data Score: -0.2028256166826352\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the scaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_s_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10497f34-5d9e-451f-be2e-cc7491bb42b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d39105-9abd-4a7e-b21a-1601b94d28ea",
   "metadata": {},
   "source": [
    "## Supervised Learning - Optimization attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a080106-7279-452b-8ee8-441a66f6592f",
   "metadata": {},
   "source": [
    "To optimize the performance of our machine learning model, we tried different Classifier algorithms with various hyperparameters. \n",
    "\n",
    "Optimization attempts were made using the Logistic Regression, Random Forest, Support Vector Machine, Bagging, AdaBoost and Voting classifiers. \n",
    "More classifiers we tried through Voting Classifier, the accuracy of the predictions improved to 73% ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c89cd8-5774-474c-98dc-e756f6cdf46b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1012c-b149-41f4-82eb-96f5f28f106a",
   "metadata": {},
   "source": [
    "Tried multiple attemps with different set of hyperparameters to see if the accuracy of Random Forest classifier can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d74f17e8-031f-489d-aef3-1eb7233c5fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7238458280389666\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=None, n_jobs=-1, max_depth=None, bootstrap=True).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=\"sqrt\", n_jobs=-1, max_depth=None, min_samples_split=2, bootstrap=False).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=50, max_leaf_nodes=16, n_jobs=-1).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=100, max_features=None, n_jobs=-1, max_depth=2, bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier_oa.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier_oa.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6681f-ba68-4034-8bd3-e28a3bc6d7a6",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Bagging allows training instances to be sampled several times for the same predictor. When sampling is performed with replacement, this method is called bagging. When sampling is performed without replacement, it is called pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f134fe9-88e0-4f05-88e8-1dc3f3769117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Bagging Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Bagging --> bootstrap=True: so the sample would be replaced back.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\"),\n",
    "                    n_estimators = 400, max_samples=1.0, bootstrap=True, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "\n",
    "# Commented below code as Unscaled data provided better accuracy\n",
    "# bag_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(\"Bagging Classifier - Scaled Data\")\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "# print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afd829b0-0a39-473a-8956-2adc7c887c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Bagging Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.6212437395659433\n",
      "Testing Data Score: 0.602287166454892\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pasting --> bootstrap=False: so the sample would NOT be replaced.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf_pasting = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\"),\n",
    "                    n_estimators = 400, max_samples=1.0, bootstrap=False, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf_pasting.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "# Commented below code as Unscaled data provided better accuracy\n",
    "# bag_clf_pasting.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(\"Bagging Classifier - Scaled Data\")\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "# print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d7612-4f78-4081-9c7e-efe19fe51cf0",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ac6b67a-39ac-4a38-9631-70ce1954f282",
   "metadata": {},
   "source": [
    "Boosting refers to any Ensemble method that can combine several weak learners into a strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d08f1d4-e61a-4234-b23d-85d07b98a74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "AdaBoost Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7627295492487479\n",
      "Testing Data Score: 0.7213045319779754\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "AdaBoost Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7627295492487479\n",
      "Testing Data Score: 0.7213045319779754\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - When training an AdaBoost classifier, the algorithm first trains a base classifier (Here \"Decision Tree\") and uses it to make predictions on the training set.\n",
    "#  The algorithm then increases the relative weight of misclassified training instances. Then it trains a second classifier using the updated weights and \n",
    "#  again makes predictions on the training set, updates the instance weights and so on.\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators = 400, algorithm='SAMME.R', learning_rate=0.5\n",
    "                            )\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "ada_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5de4-f1d0-464f-a881-8d16bcc6b922",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Voting Classifier\n",
    "\n",
    "We have trained a few classifiers, each one mostly achieving about 72% accuracy. Utilized the voting classifier to see better predictions among them and was able to arrive at 73% accuracy.\n",
    "\n",
    "By definition of Voting classifier, it provides a way to create a better classifier by aggregating the predictions of each classifier and predict the class that gets the most votes. This majority vote classifier is called a hard voting classifier\n",
    "\n",
    "If all classifiers are able to estimate class probabilities, then we can predict the class with the highest class probability, averaged over all the individual classifiers. This is considered to be soft voting.\n",
    "\n",
    "Clearly, we can see that Voting classifier slightly outperforms all the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fdb6853-9f91-4cbe-99cc-75ab46da2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf=LogisticRegression(random_state=1)\n",
    "rnd_clf=RandomForestClassifier(random_state=1, n_estimators=400)\n",
    "svm_clf=SVC(random_state=1, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb518988-54c0-4ae1-be35-7d4431e734ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7259635747564591\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7221516306649725\n",
      "AdaBoostClassifier 0.7289284201609487\n",
      "BaggingClassifier 0.7259635747564591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.7297755188479458\n"
     ]
    }
   ],
   "source": [
    "#Hard Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "397e341b-c4d4-44bb-9ed9-074c35a6e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7285048708174502\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7251164760694621\n",
      "AdaBoostClassifier 0.7213045319779754\n",
      "BaggingClassifier 0.7213045319779754\n",
      "VotingClassifier 0.7293519695044473\n"
     ]
    }
   ],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65136738-c613-4302-a51d-1b64ae29f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648a14c-61c7-4e6b-a899-09995ed95f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
