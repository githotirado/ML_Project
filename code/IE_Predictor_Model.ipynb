{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9cffe5-5e75-4d73-a671-de8740200892",
   "metadata": {},
   "source": [
    "# Trait Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed1213-53c0-40df-bfa4-6664880db7b0",
   "metadata": {},
   "source": [
    "Project objective was to develop the machine learning application that would predict the personality trait of a person as Introvert/Extrovert/Ambivert based on 91 personality questions. Our ML algorithm is trained based on survey with the same set of personality questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933f65c-860b-4169-b26d-c07a0b513911",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2586bf-b411-4666-baf8-4fd9b3912e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from config import driver, username, password, host, port, database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822f5d1-643a-418d-a9ba-b3a2c98e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS RDS Connection setup\n",
    "\n",
    "connection_string = f\"{driver}://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(connection_string)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9b5224-ef48-46d7-aa05-3a6f49d35d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionNum</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>\"I would never audition to be on a game show.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>\"I am not much of a flirt.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>\"I have to psych myself up before I am brave e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>\"I would hate living with room mates.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>\"I mostly listen to people in conversations.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QuestionNum                                           Question\n",
       "0          Q1     \"I would never audition to be on a game show.\"\n",
       "1          Q2                        \"I am not much of a flirt.\"\n",
       "2          Q3  \"I have to psych myself up before I am brave e...\n",
       "3          Q4             \"I would hate living with room mates.\"\n",
       "4          Q5      \"I mostly listen to people in conversations.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Questions list from AWS RDS\n",
    "\n",
    "QuestionsListDF = pd.read_sql_table('questionslist', connection)\n",
    "QuestionsListDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ecc887-c5f4-4963-ba0d-6a28ebfc34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_columns = 300\n",
    "# pd.options.display.max_columns = 100\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f0ac432-28c8-4805-aa74-7ad42fbde162",
   "metadata": {
    "tags": []
   },
   "source": [
    "# About the Questionnaire Survey responses data\n",
    "\n",
    "A - The user's selected response. 1=Disagree, 2=Slightly disagree, 3=Neutral, 4=Slightly agree, 5=Agree\n",
    "I - The position of the question in the survey.\n",
    "E - The time elapsed on that question in milliseconds.\n",
    "\n",
    "gender: \"What is your gender?\"\t 1=Male 2=Female 3=Other\n",
    "engnat: Is English your native language?\"\t1=Yes 2=No\n",
    "age:\"What is your age in years?\"\n",
    "introvert_extrovert:\"Do you identify as either an introvert or extravert?\"\t1=Yes, introvert 2=Yes, extravert 3=No\n",
    "country:\tuser's network location\n",
    "dateload:\tthe time the user loaded the introduction page\n",
    "introelapse:\tthe time spent in seconds on the introduction page\n",
    "testelapse:\tthe time spent in seconds on the test questions\n",
    "surveyelapse:\tthe time spent in seconds on the final page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd389bc-557c-4ef9-be7c-79fd81102340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local csv file read\n",
    "\n",
    "# QuestionnaireDF = pd.read_csv(Path('../resources/data.csv'), delimiter='\\t')\n",
    "# QuestionnaireDF.rename(columns ={'country':'COUNTRY', \n",
    "#                                  'dateload':'DATELOAD',\n",
    "#                                  'introelapse':'INTROELAPSE',\n",
    "#                                  'testelapse':'TESTELAPSE',\n",
    "#                                  'surveyelapse':'SURVEYELAPSE',\n",
    "#                                  'gender':'GENDER',\n",
    "#                                  'engnat':'ENGNAT',\n",
    "#                                  'age':'AGE',\n",
    "#                                  'IE':'INTROVERT_EXTROVERT'}, inplace=True)\n",
    "# QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035ed6e1-336b-42bc-838e-358af9beab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  ...   Q91E  \\\n",
       "0       1    5   51  7107    3   91  2522    1   56  6180  ...   4609   \n",
       "1       2    5   39  6354    5   13  3092    1   12  5243  ...  10409   \n",
       "2       3    3   17  5397    4   35  2747    5   40  5262  ...   2691   \n",
       "3       4    5   41  3055    2   14  3348    1   13  5141  ...   3697   \n",
       "4       5    1   76  2542    2   54  1878    1   15  5637  ...   1662   \n",
       "\n",
       "   COUNTRY            DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  GENDER  \\\n",
       "0       US 2019-02-20 17:35:52            1         461            16       2   \n",
       "1       AU 2019-02-20 17:46:32           21         467            15       1   \n",
       "2       BR 2019-02-20 18:10:24           56         306            17       1   \n",
       "3       CZ 2019-02-20 18:16:21            2         287            14       1   \n",
       "4       CA 2019-02-20 18:21:49            2         325            12       1   \n",
       "\n",
       "   ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0       1   23                    3  \n",
       "1       2   25                    2  \n",
       "2       2   19                    1  \n",
       "3       1   23                    1  \n",
       "4       1   18                    2  \n",
       "\n",
       "[5 rows x 283 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Questionnaire Survey Dataset from AWS RDS\n",
    "\n",
    "QuestionnaireDF = pd.read_sql_table('questionnaire', connection)\n",
    "QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842032-4b2a-4de8-84c3-2f76cd9134fc",
   "metadata": {},
   "source": [
    "## Preprocessing: Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758b3201-edd4-474e-b6fb-a783a64bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>7184</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>7185</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>7186</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>7187</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>7188</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7163 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  ...   Q91E  \\\n",
       "0          1    5   51  7107    3   91  2522    1   56   6180  ...   4609   \n",
       "1          2    5   39  6354    5   13  3092    1   12   5243  ...  10409   \n",
       "2          3    3   17  5397    4   35  2747    5   40   5262  ...   2691   \n",
       "3          4    5   41  3055    2   14  3348    1   13   5141  ...   3697   \n",
       "4          5    1   76  2542    2   54  1878    1   15   5637  ...   1662   \n",
       "...      ...  ...  ...   ...  ...  ...   ...  ...  ...    ...  ...    ...   \n",
       "7183    7184    1   46  1328    4   82  3214    4   43   3360  ...   3495   \n",
       "7184    7185    2    5  8786    5   24  2233    5   10  10387  ...   6088   \n",
       "7185    7186    3   29  6618    5   44  2393    4   58   5768  ...   3425   \n",
       "7186    7187    4   15  8321    2   18  6179    5   60   5037  ...  17416   \n",
       "7187    7188    5   57  2950    2   66  2232    4   24   7095  ...   1901   \n",
       "\n",
       "      COUNTRY            DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US 2019-02-20 17:35:52            1         461            16   \n",
       "1          AU 2019-02-20 17:46:32           21         467            15   \n",
       "2          BR 2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ 2019-02-20 18:16:21            2         287            14   \n",
       "4          CA 2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                 ...          ...         ...           ...   \n",
       "7183       US 2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA 2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY 2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA 2019-08-19 15:19:35            3         414            23   \n",
       "7187       US 2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7163 rows x 283 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the rows that are not contributing to Classification values \"Introvert/Extrovert/Ambivert\" \n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.loc[QuestionnaireDF['INTROVERT_EXTROVERT'] != 0]\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014b0fe3-98f4-41d6-8a66-d6a9a46f84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q90I</th>\n",
       "      <th>Q90E</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>Q91I</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4648</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3884</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10409</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2345</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>6413</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  Q4A  ...  Q90A  Q90I  Q90E  \\\n",
       "0    5   51  7107    3   91  2522    1   56  6180    2  ...     3    40  4648   \n",
       "1    5   39  6354    5   13  3092    1   12  5243    5  ...     4    28  3884   \n",
       "2    3   17  5397    4   35  2747    5   40  5262    3  ...     1    87  1759   \n",
       "3    5   41  3055    2   14  3348    1   13  5141    1  ...     3    15  2345   \n",
       "4    1   76  2542    2   54  1878    1   15  5637    1  ...     5    86  6413   \n",
       "\n",
       "   Q91A  Q91I   Q91E  GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0     3    35   4609       2       1   23                    3  \n",
       "1     3     1  10409       1       2   25                    2  \n",
       "2     1    19   2691       1       2   19                    1  \n",
       "3     3    23   3697       1       1   23                    1  \n",
       "4     5    69   1662       1       1   18                    2  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only features that are considered to be important for training the model\n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.drop(columns=['row_id','COUNTRY', 'DATELOAD', 'INTROELAPSE', 'TESTELAPSE', 'SURVEYELAPSE'])\n",
    "QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a15c57e-f4b3-4fee-a586-0c76bf0a0e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     14,      15,      16,      17,      18,      19,      20,\n",
       "            21,      22,      23,      24,      25,      26,      27,\n",
       "            28,      29,      30,      31,      32,      33,      34,\n",
       "            35,      36,      37,      38,      39,      40,      41,\n",
       "            42,      43,      44,      45,      46,      47,      48,\n",
       "            49,      50,      51,      52,      53,      54,      55,\n",
       "            56,      57,      58,      59,      60,      61,      62,\n",
       "            63,      64,      65,      66,      67,      68,      69,\n",
       "            70,      71,      72,      73,      75,      77,      78,\n",
       "            79,      81,      90,     255,    1979,    1983,    1990,\n",
       "          1991,    1996,    1999,    2003, 8675309], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the data in the selected features\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4128fcc0-a29f-48fc-95d7-87e417e9b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for cleaning age feature. Drop rows with age above max_age\n",
    "\n",
    "max_age = 100\n",
    "# Age: Clean up invalid rows where age is above max_age\n",
    "age_range = (QuestionnaireDF['AGE'] < max_age)\n",
    "QuestionnaireDF = QuestionnaireDF.loc[age_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b76c0a5-9a1a-486b-b342-10ea554da41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "       48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 81, 90],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF values after the age clean up\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e89df7-0229-4166-8564-f653b9880dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Selecting only the response columns from the dataframe. Ignoring the columns with Question sequence and response time.\n",
    "\n",
    "ColumnsList = QuestionnaireDF.columns.to_list()\n",
    "\n",
    "surveyResponseColumnsList = []\n",
    "for column in ColumnsList:\n",
    "    if (column[0] == 'Q' and column[-1] == 'A'):\n",
    "        surveyResponseColumnsList.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f546b3-2155-4435-91ea-6374a324d4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsList = []\n",
    "# for column in ColumnsList:\n",
    "#     if (column[0] == 'Q' and column[-1] == 'E'):\n",
    "#         elapsedTimeColumnsList.append(column)\n",
    "        \n",
    "# elapsedTimeColumnsList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e432a4e-0aa9-4b0e-8dbe-6ea776e5df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsDF = QuestionnaireDF[['Q1E', 'Q2E', 'Q3E', 'Q4E', 'Q5E']]\n",
    "# elapsedTimeColumnsDF = QuestionnaireDF[elapsedTimeColumnsList]\n",
    "# elapsedTimeColumnsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7a3c6b-37b5-4359-8589-9f8f038677e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 Minute = 60 Seconds = 60,000 Milliseconds\n",
    "# Identify all rows that have atleast one response time more than 1 minute\n",
    "\n",
    "# elapsedTimeColumnsDF['Q1E'].loc[lambda x : x > 60000]\n",
    "# outliersDF = elapsedTimeColumnsDF[elapsedTimeColumnsDF.gt(60000).any(axis=1)]\n",
    "# outliersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276bd704-f25e-4a76-adcc-f1461996cbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outliersinSecondsDF=outliersDF/1000\n",
    "# outliersinSecondsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98be2f21-1c42-4c42-b8fa-0e00803ccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     3     2   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     2     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     3     1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     3     5   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     5   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     4     5   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     4     4   \n",
       "\n",
       "      Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0        1     4     2     5     4     3     3                    3  \n",
       "1        2     1     3     4     4     4     3                    2  \n",
       "2        5     4     5     3     2     1     1                    1  \n",
       "3        5     3     5     4     4     3     3                    1  \n",
       "4        1     3     1     2     5     5     5                    2  \n",
       "...    ...   ...   ...   ...   ...   ...   ...                  ...  \n",
       "7183     3     4     3     4     2     5     4                    1  \n",
       "7184     4     5     4     3     1     3     2                    1  \n",
       "7185     5     4     5     3     1     1     1                    1  \n",
       "7186     1     4     1     1     4     5     2                    1  \n",
       "7187     2     4     3     5     4     4     4                    1  \n",
       "\n",
       "[7153 rows x 92 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Cleansed DF for Machine Learning. Since the data is already numeric, there is no need to convert the categorical data to numeric.\n",
    "\n",
    "CleansedDF = QuestionnaireDF[surveyResponseColumnsList].copy()\n",
    "\n",
    "#Initially we thought of using Gender, English Language and Age for Predicting the personality. But later we changed our thoughts.\n",
    "# CleansedDF['GENDER'] = QuestionnaireDF['GENDER']\n",
    "# CleansedDF['ENGNAT'] = QuestionnaireDF['ENGNAT']\n",
    "# CleansedDF['AGE'] = QuestionnaireDF['AGE']\n",
    "\n",
    "CleansedDF['INTROVERT_EXTROVERT'] = QuestionnaireDF['INTROVERT_EXTROVERT']\n",
    "\n",
    "CleansedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fcd34-1cb2-45ac-8b24-51e4b677fd8a",
   "metadata": {},
   "source": [
    "## Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a6311a-54c8-48fc-8e05-1f65e5038b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  Q85A  \\\n",
       "0    5    3    1    2    3    2    3    3    4     5  ...     3     2     1   \n",
       "1    5    5    1    5    2    2    5    2    1     3  ...     2     2     2   \n",
       "2    3    4    5    3    4    5    5    5    5     5  ...     5     5     5   \n",
       "3    5    2    1    1    5    5    5    4    4     2  ...     5     5     5   \n",
       "4    1    2    1    1    3    3    5    1    3     4  ...     3     1     1   \n",
       "\n",
       "   Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0     4     2     5     4     3     3                    3  \n",
       "1     1     3     4     4     4     3                    2  \n",
       "2     4     5     3     2     1     1                    1  \n",
       "3     3     5     4     4     3     3                    1  \n",
       "4     3     1     2     5     5     5                    2  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleansedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154f54cd-651d-46f5-b713-4d40e4be1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q82A</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q82A  Q83A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     1     3   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     1     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     2     3   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     4     3   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     3   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     5     4   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     3     4   \n",
       "\n",
       "      Q84A  Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  \n",
       "0        2     1     4     2     5     4     3     3  \n",
       "1        2     2     1     3     4     4     4     3  \n",
       "2        5     5     4     5     3     2     1     1  \n",
       "3        5     5     3     5     4     4     3     3  \n",
       "4        1     1     3     1     2     5     5     5  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7183     5     3     4     3     4     2     5     4  \n",
       "7184     5     4     5     4     3     1     3     2  \n",
       "7185     5     5     4     5     3     1     1     1  \n",
       "7186     5     1     4     1     1     4     5     2  \n",
       "7187     4     2     4     3     5     4     4     4  \n",
       "\n",
       "[7153 rows x 91 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features data for training the model\n",
    "\n",
    "X = CleansedDF.drop(columns=['INTROVERT_EXTROVERT'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8a8323-13ff-42b4-802a-51866db1382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "7183    1\n",
       "7184    1\n",
       "7185    1\n",
       "7186    1\n",
       "7187    1\n",
       "Name: INTROVERT_EXTROVERT, Length: 7153, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate classification label for training the model\n",
    "\n",
    "y = CleansedDF['INTROVERT_EXTROVERT']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246ea1e0-28dc-408f-bb53-4fe18c29e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd979bc-dd76-4593-933d-e1ffc53d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape: (4792, 91) \n",
      "X_Train Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n",
      "X_Test Shape: (2361, 91) \n",
      "X_Test Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data dimensions.\n",
    "\n",
    "print(f\"X_Train Shape: {X_train.shape} \\nX_Train Columns: {X_train.columns}\")\n",
    "print(f\"X_Test Shape: {X_test.shape} \\nX_Test Columns: {X_test.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170b7a-8226-4edf-bd2e-0b33487d8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised Learning - K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97824f2e-2386-413d-a8a6-8ce2e7388f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elbow Curve based on K-Means Algorithm shows there would be 3 clusters in the dataset. This can be understood as three classes - Introvert, Extrovert and Ambivert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4823a2-0e0d-42af-8533-540b5a208f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the best value for _k_ using the Elbow Curve\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5533b8a0-e842-41b6-9a43-ea13dfa89e60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow curve to identify the best number of clusters\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'], color='#DA665D')\n",
    "plt.xticks(k)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot for k-Means Cluster Analysis')\n",
    "plt.savefig('../Images/Elbow-plot-k-Means-Cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a8cad-b2b8-464c-8bf3-ad534d4fad5c",
   "metadata": {},
   "source": [
    "## Supervised Learning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0e6bc2c-fc8b-4a7b-939d-ff6a24c9addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d028a8e-d260-42c8-92e8-2ccd01710958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "\n",
    "filename = '../saved_models/IE_Predictor_model.sav'\n",
    "pickle.dump(rf_uns_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6980e60-7dc1-4903-9b6a-559d7e3b7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics and plot the matrix\n",
    "\n",
    "y_pred = rf_uns_classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=rf_uns_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=rf_uns_classifier.classes_)\n",
    "\n",
    "# ml_cmap = ListedColormap(['#DA665D', '#D7BE48', '#2B62BA'])\n",
    "\n",
    "# To maintain uniformity, setting up tableau colors to each bin so we have different colors for True predictions.\n",
    "# True Introverts, True Extroverts, True Ambiverts\n",
    "ml_cmap = ListedColormap(['#F8F8FF', '#DA665D', '#D7BE48', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#F8F8FF', '#2B62BA', '#2B62BA'])\n",
    "\n",
    "disp.plot(cmap = ml_cmap)\n",
    "\n",
    "plt.title('1:Introvert, 2:Extrovert, 3:Ambivert')\n",
    "plt.savefig(\"../images/ConfMatrix-Introvert-Extrovert-Ambivert.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0795f71-23ce-42ae-9f16-1577040e1708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72469\n"
     ]
    }
   ],
   "source": [
    "# True Introverts, True Entroverts, True Ambiverts\n",
    "# accuracy = (tp + tn) / (tp + fp + tn + fn) \n",
    "\n",
    "ti, fi1, fi2, fe1, te, fe2, fa1, fa2, ta = confusion_matrix(y_test, y_pred).ravel()\n",
    "accuracy = (ti + te +ta) / (ti + fi1 + fi2 + fe1 + te + fe2 + fa1 + fa2 + ta) \n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50564db4-87cb-4df1-871d-01c63b827591",
   "metadata": {},
   "source": [
    "Since we are trying to predict more than 2 classes, the metrics cannot be calculated as average=Binary. All the 4 metrics Accuracy, Precision, Recall and F1 Score seem to good when they are calculated using \"MICRO\", \"MACRO\", \"WEIGHTED\", MICRO seems to be provide the higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04458070-d075-4e8f-be49-eb5dbd0ed8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "\n",
      "Metrics of Random Forest Classifier Model: Average=micro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.72469\n",
      "Recall = 0.72469\n",
      "F1 score = 0.72469\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the Random Forest Classifier model\n",
    "print('---------------------------------------------------------')\n",
    "print('\\nMetrics of Random Forest Classifier Model: Average=micro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4ad105-3612-4166-ba43-ce8f58ba704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=macro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.67142\n",
      "Recall = 0.61126\n",
      "F1 score = 0.63114\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=macro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5294dc5f-9d08-41e1-89f4-edc97938a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=weighted\n",
      "-----------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.70263\n",
      "Recall = 0.72469\n",
      "F1 score = 0.70506\n",
      "-----------------------------------------------------------\n",
      "Classification Report\n",
      "-----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=weighted')\n",
    "print('-----------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('-----------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03271e44-9357-4dea-aa01-48475e98cdc8",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26ffd950-d382-4c4e-b564-fbfceebb2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baf1db-5a4f-4a4a-8546-d6e65a3ce893",
   "metadata": {},
   "source": [
    "## Random Forest on Scaled data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c2f378f-1f7b-443c-8088-107cae5c922e",
   "metadata": {},
   "source": [
    "We can see that there is no impact of scaling on the accuracy score in case of Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5897da-2990-41e8-8f7f-00730d1572be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_s_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train_scaled, y_train)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dc684-14ed-4e8c-903f-8f9567605f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827c914-cb50-4144-846f-8714c8053805",
   "metadata": {},
   "source": [
    "Logistic Regression has better performance over Random Forest classifier. Scaled data has little better accuracy over the Unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfb0d6cb-66b1-4f52-a3db-e2bf2793c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7765025041736227\n",
      "Testing Data Score: 0.7259635747564591\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_uns_classifier = LogisticRegression(random_state=1)\n",
    "lr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3097f58-d739-46d9-b218-dedc2888021a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7773372287145242\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_s_classifier = LogisticRegression(random_state=1)\n",
    "lr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb867c79-6066-48da-92da-935b0dccaba1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f935baf-8c8c-464f-b3cd-e125d4422678",
   "metadata": {},
   "source": [
    "Definitely Linear Regression has very low accracy and would definitely not be considered for any predictions in this app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f56d6d06-d148-44e6-98d1-7b8e3cf822a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.29771414306965005\n",
      "Testing Data Score: 0.23095512862618128\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the unscaled data and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_uns_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b160811-ce66-4561-a2ac-fe1ab526823e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: -0.18858285304377498\n",
      "Testing Data Score: -0.2028256166826352\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the scaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_s_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10497f34-5d9e-451f-be2e-cc7491bb42b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d39105-9abd-4a7e-b21a-1601b94d28ea",
   "metadata": {},
   "source": [
    "## Supervised Learning - Optimization attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a080106-7279-452b-8ee8-441a66f6592f",
   "metadata": {},
   "source": [
    "To optimize the performance of our machine learning model, we tried different Classifier algorithms with various hyperparameters. \n",
    "\n",
    "Optimization attempts were made using the Logistic Regression, Random Forest, Support Vector Machine, Bagging, AdaBoost and Voting classifiers. \n",
    "More classifiers we tried through Voting Classifier, the accuracy of the predictions improved to 73% ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c89cd8-5774-474c-98dc-e756f6cdf46b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1012c-b149-41f4-82eb-96f5f28f106a",
   "metadata": {},
   "source": [
    "Tried multiple attemps with different set of hyperparameters to see if the accuracy of Random Forest classifier can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d74f17e8-031f-489d-aef3-1eb7233c5fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7238458280389666\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=None, n_jobs=-1, max_depth=None, bootstrap=True).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=\"sqrt\", n_jobs=-1, max_depth=None, min_samples_split=2, bootstrap=False).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=50, max_leaf_nodes=16, n_jobs=-1).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=100, max_features=None, n_jobs=-1, max_depth=2, bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier_oa.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier_oa.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6681f-ba68-4034-8bd3-e28a3bc6d7a6",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Bagging allows training instances to be sampled several times for the same predictor. When sampling is performed with replacement, this method is called bagging. When sampling is performed without replacement, it is called pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f134fe9-88e0-4f05-88e8-1dc3f3769117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Bagging Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Bagging --> bootstrap=True: so the sample would be replaced back.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\"),\n",
    "                    n_estimators = 400, max_samples=1.0, bootstrap=True, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "\n",
    "# Commented below code as Unscaled data provided better accuracy\n",
    "# bag_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(\"Bagging Classifier - Scaled Data\")\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "# print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afd829b0-0a39-473a-8956-2adc7c887c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Bagging Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.6212437395659433\n",
      "Testing Data Score: 0.602287166454892\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pasting --> bootstrap=False: so the sample would NOT be replaced.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf_pasting = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\"),\n",
    "                    n_estimators = 400, max_samples=1.0, bootstrap=False, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf_pasting.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "# Commented below code as Unscaled data provided better accuracy\n",
    "# bag_clf_pasting.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(\"Bagging Classifier - Scaled Data\")\n",
    "# print(\"----------------------------------------------\")\n",
    "# print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "# print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "# print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d7612-4f78-4081-9c7e-efe19fe51cf0",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ac6b67a-39ac-4a38-9631-70ce1954f282",
   "metadata": {},
   "source": [
    "Boosting refers to any Ensemble method that can combine several weak learners into a strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d08f1d4-e61a-4234-b23d-85d07b98a74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "AdaBoost Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7627295492487479\n",
      "Testing Data Score: 0.7213045319779754\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "AdaBoost Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7627295492487479\n",
      "Testing Data Score: 0.7213045319779754\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - When training an AdaBoost classifier, the algorithm first trains a base classifier (Here \"Decision Tree\") and uses it to make predictions on the training set.\n",
    "#  The algorithm then increases the relative weight of misclassified training instances. Then it trains a second classifier using the updated weights and \n",
    "#  again makes predictions on the training set, updates the instance weights and so on.\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators = 400, algorithm='SAMME.R', learning_rate=0.5\n",
    "                            )\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "ada_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5de4-f1d0-464f-a881-8d16bcc6b922",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Voting Classifier\n",
    "\n",
    "We have trained a few classifiers, each one mostly achieving about 72% accuracy. Utilized the voting classifier to see better predictions among them and was able to arrive at 73% accuracy.\n",
    "\n",
    "By definition of Voting classifier, it provides a way to create a better classifier by aggregating the predictions of each classifier and predict the class that gets the most votes. This majority vote classifier is called a hard voting classifier\n",
    "\n",
    "If all classifiers are able to estimate class probabilities, then we can predict the class with the highest class probability, averaged over all the individual classifiers. This is considered to be soft voting.\n",
    "\n",
    "Clearly, we can see that Voting classifier slightly outperforms all the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fdb6853-9f91-4cbe-99cc-75ab46da2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf=LogisticRegression(random_state=1)\n",
    "rnd_clf=RandomForestClassifier(random_state=1, n_estimators=400)\n",
    "svm_clf=SVC(random_state=1, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb518988-54c0-4ae1-be35-7d4431e734ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7259635747564591\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7221516306649725\n",
      "AdaBoostClassifier 0.7289284201609487\n",
      "BaggingClassifier 0.7259635747564591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.7297755188479458\n"
     ]
    }
   ],
   "source": [
    "#Hard Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "397e341b-c4d4-44bb-9ed9-074c35a6e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7285048708174502\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7251164760694621\n",
      "AdaBoostClassifier 0.7213045319779754\n",
      "BaggingClassifier 0.7213045319779754\n",
      "VotingClassifier 0.7293519695044473\n"
     ]
    }
   ],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65136738-c613-4302-a51d-1b64ae29f5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7259635747564591\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7221516306649725\n",
      "AdaBoostClassifier 0.7213045319779754\n",
      "BaggingClassifier 0.7229987293519695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.7285048708174502\n"
     ]
    }
   ],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648a14c-61c7-4e6b-a899-09995ed95f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
