{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9cffe5-5e75-4d73-a671-de8740200892",
   "metadata": {},
   "source": [
    "# Trait Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed1213-53c0-40df-bfa4-6664880db7b0",
   "metadata": {},
   "source": [
    "Project objective was to develop the machine learning application that would predict the personality trait of a person as Introvert/Extrovert/Ambivert based on 91 personality questions. Our ML algorithm is trained based on survey with the same set of personality questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933f65c-860b-4169-b26d-c07a0b513911",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2586bf-b411-4666-baf8-4fd9b3912e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from config import driver, username, password, host, port, database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822f5d1-643a-418d-a9ba-b3a2c98e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"{driver}://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(connection_string)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9b5224-ef48-46d7-aa05-3a6f49d35d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QuestionsListDF = pd.read_sql_table('questionslist', connection)\n",
    "# QuestionsListDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ecc887-c5f4-4963-ba0d-6a28ebfc34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_columns = 300\n",
    "# pd.options.display.max_columns = 100\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f0ac432-28c8-4805-aa74-7ad42fbde162",
   "metadata": {
    "tags": []
   },
   "source": [
    "# About the Questionnaire Survey responses data\n",
    "\n",
    "A - The user's selected response. 1=Disagree, 2=Slightly disagree, 3=Neutral, 4=Slightly agree, 5=Agree\n",
    "I - The position of the question in the survey.\n",
    "E - The time elapsed on that question in milliseconds.\n",
    "\n",
    "gender: \"What is your gender?\"\t 1=Male 2=Female 3=Other\n",
    "engnat: Is English your native language?\"\t1=Yes 2=No\n",
    "age:\"What is your age in years?\"\n",
    "introvert_extrovert:\"Do you identify as either an introvert or extravert?\"\t1=Yes, introvert 2=Yes, extravert 3=No\n",
    "country:\tuser's network location\n",
    "dateload:\tthe time the user loaded the introduction page\n",
    "introelapse:\tthe time spent in seconds on the introduction page\n",
    "testelapse:\tthe time spent in seconds on the test questions\n",
    "surveyelapse:\tthe time spent in seconds on the final page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd389bc-557c-4ef9-be7c-79fd81102340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7188 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7188 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local csv file read\n",
    "\n",
    "QuestionnaireDF = pd.read_csv(Path('../resources/data.csv'), delimiter='\\t')\n",
    "QuestionnaireDF.rename(columns ={'country':'COUNTRY', \n",
    "                                 'dateload':'DATELOAD',\n",
    "                                 'introelapse':'INTROELAPSE',\n",
    "                                 'testelapse':'TESTELAPSE',\n",
    "                                 'surveyelapse':'SURVEYELAPSE',\n",
    "                                 'gender':'GENDER',\n",
    "                                 'engnat':'ENGNAT',\n",
    "                                 'age':'AGE',\n",
    "                                 'IE':'INTROVERT_EXTROVERT'}, inplace=True)\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035ed6e1-336b-42bc-838e-358af9beab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from AWS\n",
    "\n",
    "# QuestionnaireDF = pd.read_sql_table('questionnaire', connection)\n",
    "# QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842032-4b2a-4de8-84c3-2f76cd9134fc",
   "metadata": {},
   "source": [
    "## Preprocessing: Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758b3201-edd4-474e-b6fb-a783a64bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7163 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7163 rows x 282 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the rows that are not contributing to Classification values \"Introvert/Extrovert/Ambivert\" \n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.loc[QuestionnaireDF['INTROVERT_EXTROVERT'] != 0]\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014b0fe3-98f4-41d6-8a66-d6a9a46f84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q90I</th>\n",
       "      <th>Q90E</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>Q91I</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4648</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3884</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10409</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2345</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>6413</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  Q4A  ...  Q90A  Q90I  Q90E  \\\n",
       "0    5   51  7107    3   91  2522    1   56  6180    2  ...     3    40  4648   \n",
       "1    5   39  6354    5   13  3092    1   12  5243    5  ...     4    28  3884   \n",
       "2    3   17  5397    4   35  2747    5   40  5262    3  ...     1    87  1759   \n",
       "3    5   41  3055    2   14  3348    1   13  5141    1  ...     3    15  2345   \n",
       "4    1   76  2542    2   54  1878    1   15  5637    1  ...     5    86  6413   \n",
       "\n",
       "   Q91A  Q91I   Q91E  GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0     3    35   4609       2       1   23                    3  \n",
       "1     3     1  10409       1       2   25                    2  \n",
       "2     1    19   2691       1       2   19                    1  \n",
       "3     3    23   3697       1       1   23                    1  \n",
       "4     5    69   1662       1       1   18                    2  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only features that are considered to be important for training the model\n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.drop(columns=['COUNTRY', 'DATELOAD', 'INTROELAPSE', 'TESTELAPSE', 'SURVEYELAPSE'])\n",
    "QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a15c57e-f4b3-4fee-a586-0c76bf0a0e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     14,      15,      16,      17,      18,      19,      20,\n",
       "            21,      22,      23,      24,      25,      26,      27,\n",
       "            28,      29,      30,      31,      32,      33,      34,\n",
       "            35,      36,      37,      38,      39,      40,      41,\n",
       "            42,      43,      44,      45,      46,      47,      48,\n",
       "            49,      50,      51,      52,      53,      54,      55,\n",
       "            56,      57,      58,      59,      60,      61,      62,\n",
       "            63,      64,      65,      66,      67,      68,      69,\n",
       "            70,      71,      72,      73,      75,      77,      78,\n",
       "            79,      81,      90,     255,    1979,    1983,    1990,\n",
       "          1991,    1996,    1999,    2003, 8675309], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the data in the selected features\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4128fcc0-a29f-48fc-95d7-87e417e9b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for cleaning age feature. Drop rows with age above max_age\n",
    "\n",
    "max_age = 100\n",
    "# Age: Clean up invalid rows where age is above max_age\n",
    "age_range = (QuestionnaireDF['AGE'] < max_age)\n",
    "QuestionnaireDF = QuestionnaireDF.loc[age_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b76c0a5-9a1a-486b-b342-10ea554da41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "       48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 81, 90],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF values after the age clean up\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e89df7-0229-4166-8564-f653b9880dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1A',\n",
       " 'Q2A',\n",
       " 'Q3A',\n",
       " 'Q4A',\n",
       " 'Q5A',\n",
       " 'Q6A',\n",
       " 'Q7A',\n",
       " 'Q8A',\n",
       " 'Q9A',\n",
       " 'Q10A',\n",
       " 'Q11A',\n",
       " 'Q12A',\n",
       " 'Q13A',\n",
       " 'Q14A',\n",
       " 'Q15A',\n",
       " 'Q16A',\n",
       " 'Q17A',\n",
       " 'Q18A',\n",
       " 'Q19A',\n",
       " 'Q20A',\n",
       " 'Q21A',\n",
       " 'Q22A',\n",
       " 'Q23A',\n",
       " 'Q24A',\n",
       " 'Q25A',\n",
       " 'Q26A',\n",
       " 'Q27A',\n",
       " 'Q28A',\n",
       " 'Q29A',\n",
       " 'Q30A',\n",
       " 'Q31A',\n",
       " 'Q32A',\n",
       " 'Q33A',\n",
       " 'Q34A',\n",
       " 'Q35A',\n",
       " 'Q36A',\n",
       " 'Q37A',\n",
       " 'Q38A',\n",
       " 'Q39A',\n",
       " 'Q40A',\n",
       " 'Q41A',\n",
       " 'Q42A',\n",
       " 'Q43A',\n",
       " 'Q44A',\n",
       " 'Q45A',\n",
       " 'Q46A',\n",
       " 'Q47A',\n",
       " 'Q48A',\n",
       " 'Q49A',\n",
       " 'Q50A',\n",
       " 'Q51A',\n",
       " 'Q52A',\n",
       " 'Q53A',\n",
       " 'Q54A',\n",
       " 'Q55A',\n",
       " 'Q56A',\n",
       " 'Q57A',\n",
       " 'Q58A',\n",
       " 'Q59A',\n",
       " 'Q60A',\n",
       " 'Q61A',\n",
       " 'Q62A',\n",
       " 'Q63A',\n",
       " 'Q64A',\n",
       " 'Q65A',\n",
       " 'Q66A',\n",
       " 'Q67A',\n",
       " 'Q68A',\n",
       " 'Q69A',\n",
       " 'Q70A',\n",
       " 'Q71A',\n",
       " 'Q72A',\n",
       " 'Q73A',\n",
       " 'Q74A',\n",
       " 'Q75A',\n",
       " 'Q76A',\n",
       " 'Q77A',\n",
       " 'Q78A',\n",
       " 'Q79A',\n",
       " 'Q80A',\n",
       " 'Q81A',\n",
       " 'Q82A',\n",
       " 'Q83A',\n",
       " 'Q84A',\n",
       " 'Q85A',\n",
       " 'Q86A',\n",
       " 'Q87A',\n",
       " 'Q88A',\n",
       " 'Q89A',\n",
       " 'Q90A',\n",
       " 'Q91A']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Selecting only the response columns from the dataframe. Ignoring the columns with Question sequence and response time.\n",
    "\n",
    "ColumnsList = QuestionnaireDF.columns.to_list()\n",
    "\n",
    "surveyResponseColumnsList = []\n",
    "for column in ColumnsList:\n",
    "    if (column[0] == 'Q' and column[-1] == 'A'):\n",
    "        surveyResponseColumnsList.append(column)\n",
    "\n",
    "surveyResponseColumnsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f546b3-2155-4435-91ea-6374a324d4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsList = []\n",
    "# for column in ColumnsList:\n",
    "#     if (column[0] == 'Q' and column[-1] == 'E'):\n",
    "#         elapsedTimeColumnsList.append(column)\n",
    "        \n",
    "# elapsedTimeColumnsList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e432a4e-0aa9-4b0e-8dbe-6ea776e5df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsDF = QuestionnaireDF[['Q1E', 'Q2E', 'Q3E', 'Q4E', 'Q5E']]\n",
    "# elapsedTimeColumnsDF = QuestionnaireDF[elapsedTimeColumnsList]\n",
    "# elapsedTimeColumnsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7a3c6b-37b5-4359-8589-9f8f038677e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 Minute = 60 Seconds = 60,000 Milliseconds\n",
    "# Identify all rows that have atleast one response time more than 1 minute\n",
    "\n",
    "# elapsedTimeColumnsDF['Q1E'].loc[lambda x : x > 60000]\n",
    "# outliersDF = elapsedTimeColumnsDF[elapsedTimeColumnsDF.gt(60000).any(axis=1)]\n",
    "# outliersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276bd704-f25e-4a76-adcc-f1461996cbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outliersinSecondsDF=outliersDF/1000\n",
    "# outliersinSecondsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98be2f21-1c42-4c42-b8fa-0e00803ccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     3     2   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     2     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     3     1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     3     5   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     5   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     4     5   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     4     4   \n",
       "\n",
       "      Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0        1     4     2     5     4     3     3                    3  \n",
       "1        2     1     3     4     4     4     3                    2  \n",
       "2        5     4     5     3     2     1     1                    1  \n",
       "3        5     3     5     4     4     3     3                    1  \n",
       "4        1     3     1     2     5     5     5                    2  \n",
       "...    ...   ...   ...   ...   ...   ...   ...                  ...  \n",
       "7183     3     4     3     4     2     5     4                    1  \n",
       "7184     4     5     4     3     1     3     2                    1  \n",
       "7185     5     4     5     3     1     1     1                    1  \n",
       "7186     1     4     1     1     4     5     2                    1  \n",
       "7187     2     4     3     5     4     4     4                    1  \n",
       "\n",
       "[7153 rows x 92 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Cleansed DF for Machine Learning. Since the data is already numeric, there is no need to convert the categorical data to numeric.\n",
    "\n",
    "CleansedDF = QuestionnaireDF[surveyResponseColumnsList].copy()\n",
    "\n",
    "#Initially we thought of using Gender, English Language and Age for Predicting the personality. But later we changed our thoughts.\n",
    "# CleansedDF['GENDER'] = QuestionnaireDF['GENDER']\n",
    "# CleansedDF['ENGNAT'] = QuestionnaireDF['ENGNAT']\n",
    "# CleansedDF['AGE'] = QuestionnaireDF['AGE']\n",
    "\n",
    "CleansedDF['INTROVERT_EXTROVERT'] = QuestionnaireDF['INTROVERT_EXTROVERT']\n",
    "\n",
    "CleansedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fcd34-1cb2-45ac-8b24-51e4b677fd8a",
   "metadata": {},
   "source": [
    "## Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a6311a-54c8-48fc-8e05-1f65e5038b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  Q85A  \\\n",
       "0    5    3    1    2    3    2    3    3    4     5  ...     3     2     1   \n",
       "1    5    5    1    5    2    2    5    2    1     3  ...     2     2     2   \n",
       "2    3    4    5    3    4    5    5    5    5     5  ...     5     5     5   \n",
       "3    5    2    1    1    5    5    5    4    4     2  ...     5     5     5   \n",
       "4    1    2    1    1    3    3    5    1    3     4  ...     3     1     1   \n",
       "\n",
       "   Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0     4     2     5     4     3     3                    3  \n",
       "1     1     3     4     4     4     3                    2  \n",
       "2     4     5     3     2     1     1                    1  \n",
       "3     3     5     4     4     3     3                    1  \n",
       "4     3     1     2     5     5     5                    2  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleansedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154f54cd-651d-46f5-b713-4d40e4be1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q82A</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q82A  Q83A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     1     3   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     1     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     2     3   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     4     3   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     3   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     5     4   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     3     4   \n",
       "\n",
       "      Q84A  Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  \n",
       "0        2     1     4     2     5     4     3     3  \n",
       "1        2     2     1     3     4     4     4     3  \n",
       "2        5     5     4     5     3     2     1     1  \n",
       "3        5     5     3     5     4     4     3     3  \n",
       "4        1     1     3     1     2     5     5     5  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7183     5     3     4     3     4     2     5     4  \n",
       "7184     5     4     5     4     3     1     3     2  \n",
       "7185     5     5     4     5     3     1     1     1  \n",
       "7186     5     1     4     1     1     4     5     2  \n",
       "7187     4     2     4     3     5     4     4     4  \n",
       "\n",
       "[7153 rows x 91 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features data for training the model\n",
    "\n",
    "X = CleansedDF.drop(columns=['INTROVERT_EXTROVERT'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8a8323-13ff-42b4-802a-51866db1382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "7183    1\n",
       "7184    1\n",
       "7185    1\n",
       "7186    1\n",
       "7187    1\n",
       "Name: INTROVERT_EXTROVERT, Length: 7153, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate classification label for training the model\n",
    "\n",
    "y = CleansedDF['INTROVERT_EXTROVERT']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246ea1e0-28dc-408f-bb53-4fe18c29e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test datasets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cd979bc-dd76-4593-933d-e1ffc53d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape: (4792, 91) \n",
      "X_Train Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n",
      "X_Test Shape: (2361, 91) \n",
      "X_Test Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data dimensions.\n",
    "\n",
    "print(f\"X_Train Shape: {X_train.shape} \\nX_Train Columns: {X_train.columns}\")\n",
    "print(f\"X_Test Shape: {X_test.shape} \\nX_Test Columns: {X_test.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a8cad-b2b8-464c-8bf3-ad534d4fad5c",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0e6bc2c-fc8b-4a7b-939d-ff6a24c9addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d028a8e-d260-42c8-92e8-2ccd01710958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "\n",
    "filename = '../saved_models/IE_Predictor_model.sav'\n",
    "pickle.dump(rf_uns_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6980e60-7dc1-4903-9b6a-559d7e3b7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics and plot the matrix\n",
    "\n",
    "y_pred = rf_uns_classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=rf_uns_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=rf_uns_classifier.classes_)\n",
    "# disp.plot(cmap=\"PiYG\")\n",
    "# disp.plot(cmap = 'Blues')\n",
    "# disp.plot(cmap = 'CMRmap_r')\n",
    "# disp.plot(cmap = 'plasma_r')\n",
    "# disp.plot(cmap = 'RdYlBu')\n",
    "\n",
    "# ml_cmap = ListedColormap(['#DA665D', '#DA665D', '#D7BE48', '#D7BE48', '#D7BE48', '#D7BE48', '#D7BE48', '#D7BE48','#2B62BA', '#2B62BA'])\n",
    "ml_cmap = ListedColormap(['#DA665D', '#D7BE48','#2B62BA'])\n",
    "disp.plot(cmap = ml_cmap)\n",
    "\n",
    "plt.title('1:Introvert, 2:Extrovert, 3:Ambivert')\n",
    "plt.savefig(\"../images/ConfMatrix-Introvert-Extrovert-Ambivert.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0795f71-23ce-42ae-9f16-1577040e1708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72469\n"
     ]
    }
   ],
   "source": [
    "# True Introvert, True Entrovert, True Ambert\n",
    "\n",
    "ti, fi1, fi2, fe1, te, fe2, fa1, fa2, ta = confusion_matrix(y_test, y_pred).ravel()\n",
    "# accuracy = (tp + tn) / (tp + fp + tn + fn) \n",
    "accuracy = (ti + te +ta) / (ti + fi1 + fi2 + fe1 + te + fe2 + fa1 + fa2 + ta) \n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f39288fc-7871-48c5-bf04-e42c1bfb2803",
   "metadata": {},
   "source": [
    "Since we are trying to predict more than 2 classes, the metrics cannot be calculated as average=Binary. All the 4 metrics Accuracy, Precision, Recall and F1 Score seem to good when they are calculated using \"MICRO\", \"MACRO\", \"WEIGHTED\", MICRO seems to be provide the higher values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04458070-d075-4e8f-be49-eb5dbd0ed8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "\n",
      "Metrics of Random Forest Classifier Model: Average=micro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.72469\n",
      "Recall = 0.72469\n",
      "F1 score = 0.72469\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the Random Forest Classifier model\n",
    "print('---------------------------------------------------------')\n",
    "print('\\nMetrics of Random Forest Classifier Model: Average=micro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a4ad105-3612-4166-ba43-ce8f58ba704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=macro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.67142\n",
      "Recall = 0.61126\n",
      "F1 score = 0.63114\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=macro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5294dc5f-9d08-41e1-89f4-edc97938a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=weighted\n",
      "-----------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.70263\n",
      "Recall = 0.72469\n",
      "F1 score = 0.70506\n",
      "-----------------------------------------------------------\n",
      "Classification Report\n",
      "-----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=weighted')\n",
    "print('-----------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('-----------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03271e44-9357-4dea-aa01-48475e98cdc8",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26ffd950-d382-4c4e-b564-fbfceebb2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baf1db-5a4f-4a4a-8546-d6e65a3ce893",
   "metadata": {},
   "source": [
    "## Random Forest on Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a5897da-2990-41e8-8f7f-00730d1572be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_s_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train_scaled, y_train)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c2f378f-1f7b-443c-8088-107cae5c922e",
   "metadata": {},
   "source": [
    "We can see that there is no impact of scaling on the accuracy score in case of Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dc684-14ed-4e8c-903f-8f9567605f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb0d6cb-66b1-4f52-a3db-e2bf2793c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7765025041736227\n",
      "Testing Data Score: 0.7259635747564591\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_uns_classifier = LogisticRegression(random_state=1)\n",
    "lr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3097f58-d739-46d9-b218-dedc2888021a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7773372287145242\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_s_classifier = LogisticRegression(random_state=1)\n",
    "lr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb867c79-6066-48da-92da-935b0dccaba1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f56d6d06-d148-44e6-98d1-7b8e3cf822a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.29771414306965005\n",
      "Testing Data Score: 0.23095512862618128\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the unscaled data and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_uns_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b160811-ce66-4561-a2ac-fe1ab526823e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: -0.18858285304377498\n",
      "Testing Data Score: -0.2028256166826352\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the scaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_s_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170b7a-8226-4edf-bd2e-0b33487d8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised Learning - K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97824f2e-2386-413d-a8a6-8ce2e7388f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### K-Means Algorithm Analysis clearly shows that there are 3 clusters in the dataset. This can be understood as three classes - Introvert, Extrovert and Ambivert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f4823a2-0e0d-42af-8533-540b5a208f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.314372e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.128304e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.080813e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.060278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.043501e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.030424e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.019687e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.011197e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.004741e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9.990769e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k       inertia\n",
       "0   1  1.314372e+06\n",
       "1   2  1.128304e+06\n",
       "2   3  1.080813e+06\n",
       "3   4  1.060278e+06\n",
       "4   5  1.043501e+06\n",
       "5   6  1.030424e+06\n",
       "6   7  1.019687e+06\n",
       "7   8  1.011197e+06\n",
       "8   9  1.004741e+06\n",
       "9  10  9.990769e+05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best value for _k_ using the Elbow Curve\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5533b8a0-e842-41b6-9a43-ea13dfa89e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow curve to identify the best number of clusters\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'], color='#D7BE48')\n",
    "plt.xticks(k)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot for k-Means Cluster Analysis')\n",
    "plt.savefig('../Images/Elbow-plot-k-Means-Cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10497f34-5d9e-451f-be2e-cc7491bb42b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d39105-9abd-4a7e-b21a-1601b94d28ea",
   "metadata": {},
   "source": [
    "## Supervised Learning - Optimization attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c89cd8-5774-474c-98dc-e756f6cdf46b",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d74f17e8-031f-489d-aef3-1eb7233c5fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7238458280389666\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=None, n_jobs=-1, max_depth=None, bootstrap=True).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=\"sqrt\", n_jobs=-1, max_depth=None, min_samples_split=2, bootstrap=False).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=50, max_leaf_nodes=16, n_jobs=-1).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=100, max_features=None, n_jobs=-1, max_depth=2, bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier_oa.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier_oa.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6681f-ba68-4034-8bd3-e28a3bc6d7a6",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Bagging allows training instances to be sampled several times for the same predictor. When sampling is performed with replacement, this method is called bagging. When sampling is performed without replacement, it is called pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f134fe9-88e0-4f05-88e8-1dc3f3769117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Bagging Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7268106734434562\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Bagging Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7293519695044473\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\"),\n",
    "                    n_estimators = 400, max_samples=1.0, bootstrap=True, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "bag_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Bagging Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d7612-4f78-4081-9c7e-efe19fe51cf0",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ac6b67a-39ac-4a38-9631-70ce1954f282",
   "metadata": {},
   "source": [
    "Boosting refers to any Ensemble method that can combine several weak learners into a strong learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d08f1d4-e61a-4234-b23d-85d07b98a74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "AdaBoost Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7673205342237062\n",
      "Testing Data Score: 0.7289284201609487\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "AdaBoost Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7673205342237062\n",
      "Testing Data Score: 0.7289284201609487\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost - When training an AdaBoost classifier, the algorithm first trains a base classifier (Here \"Decision Tree\") and uses it to make predictions on the training set.\n",
    "#  The algorithm then increases the relative weight of misclassified training instances. Then it trains a second classifier using the updated weights and \n",
    "#  again makes predictions on the training set, updates the instance weights and so on.\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators = 200, algorithm='SAMME.R', learning_rate=0.5\n",
    "                            )\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "ada_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"AdaBoost Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5de4-f1d0-464f-a881-8d16bcc6b922",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Voting Classifier\n",
    "\n",
    "We have trained a few classifiers, each one mostly achieving about 72% accuracy. Utilized the voting classifier to see better predictions among them and was able to arrive at 73% accuracy.\n",
    "\n",
    "By definition of Voting classifier, it provides a way to create a better classifier by aggregating the predictions of each classifier and predict the class that gets the most votes. This majority vote classifier is called a hard voting classifier\n",
    "\n",
    "If all classifiers are able to estimate class probabilities, then we can predict the class with the highest class probability, averaged over all the individual classifiers. This is considered to be soft voting.\n",
    "\n",
    "Clearly, we can see that Voting classifier slightly outperforms all the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb518988-54c0-4ae1-be35-7d4431e734ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7259635747564591\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7221516306649725\n",
      "AdaBoostClassifier 0.7289284201609487\n",
      "BaggingClassifier 0.7208809826344769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.7297755188479458\n"
     ]
    }
   ],
   "source": [
    "#Hard Voting\n",
    "\n",
    "log_clf=LogisticRegression(random_state=1)\n",
    "rnd_clf=RandomForestClassifier(random_state=1, n_estimators=400)\n",
    "svm_clf=SVC(random_state=1, probability=True)\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "397e341b-c4d4-44bb-9ed9-074c35a6e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7285048708174502\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7251164760694621\n",
      "AdaBoostClassifier 0.7289284201609487\n",
      "BaggingClassifier 0.723422278695468\n",
      "VotingClassifier 0.7314697162219399\n"
     ]
    }
   ],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf), ('bc', bag_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, ada_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78a0b6-b15e-4551-9a40-7579f02e4a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
