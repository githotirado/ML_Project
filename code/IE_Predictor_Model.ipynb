{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9cffe5-5e75-4d73-a671-de8740200892",
   "metadata": {},
   "source": [
    "# IE Predictor Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f0ac432-28c8-4805-aa74-7ad42fbde162",
   "metadata": {
    "tags": []
   },
   "source": [
    "A - The user's selected response. 1=Disagree, 2=Slightly disagree, 3=Neutral, 4=Slightly agree, 5=Agree\n",
    "I - The position of the question in the survey.\n",
    "E - The time elapsed on that question in milliseconds.\n",
    "\n",
    "gender: \"What is your gender?\"\t 1=Male 2=Female 3=Other\n",
    "engnat: Is English your native language?\"\t1=Yes 2=No\n",
    "age:\"What is your age in years?\"\n",
    "introvert_extrovert:\"Do you identify as either an introvert or extravert?\"\t1=Yes, introvert 2=Yes, extravert 3=No\n",
    "country:\tuser's network location\n",
    "dateload:\tthe time the user loaded the introduction page\n",
    "introelapse:\tthe time spent in seconds on the introduction page\n",
    "testelapse:\tthe time spent in seconds on the test questions\n",
    "surveyelapse:\tthe time spent in seconds on the final page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2586bf-b411-4666-baf8-4fd9b3912e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from config import driver, username, password, host, port, database\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822f5d1-643a-418d-a9ba-b3a2c98e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"{driver}://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(connection_string)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9b5224-ef48-46d7-aa05-3a6f49d35d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QuestionsListDF = pd.read_sql_table('questionslist', connection)\n",
    "# QuestionsListDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ecc887-c5f4-4963-ba0d-6a28ebfc34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_columns = 300\n",
    "# pd.options.display.max_columns = 100\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd389bc-557c-4ef9-be7c-79fd81102340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7188 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7188 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local csv file read\n",
    "\n",
    "QuestionnaireDF = pd.read_csv(Path('../resources/data.csv'), delimiter='\\t')\n",
    "QuestionnaireDF.rename(columns ={'country':'COUNTRY', \n",
    "                                 'dateload':'DATELOAD',\n",
    "                                 'introelapse':'INTROELAPSE',\n",
    "                                 'testelapse':'TESTELAPSE',\n",
    "                                 'surveyelapse':'SURVEYELAPSE',\n",
    "                                 'gender':'GENDER',\n",
    "                                 'engnat':'ENGNAT',\n",
    "                                 'age':'AGE',\n",
    "                                 'IE':'INTROVERT_EXTROVERT'}, inplace=True)\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035ed6e1-336b-42bc-838e-358af9beab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from AWS\n",
    "\n",
    "# QuestionnaireDF = pd.read_sql_table('questionnaire', connection)\n",
    "# QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842032-4b2a-4de8-84c3-2f76cd9134fc",
   "metadata": {},
   "source": [
    "## Preprocessing - Provide output as CleansedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758b3201-edd4-474e-b6fb-a783a64bf02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DATELOAD</th>\n",
       "      <th>INTROELAPSE</th>\n",
       "      <th>TESTELAPSE</th>\n",
       "      <th>SURVEYELAPSE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4609</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-02-20 17:35:52</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>10409</td>\n",
       "      <td>AU</td>\n",
       "      <td>2019-02-20 17:46:32</td>\n",
       "      <td>21</td>\n",
       "      <td>467</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2691</td>\n",
       "      <td>BR</td>\n",
       "      <td>2019-02-20 18:10:24</td>\n",
       "      <td>56</td>\n",
       "      <td>306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3697</td>\n",
       "      <td>CZ</td>\n",
       "      <td>2019-02-20 18:16:21</td>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1662</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-02-20 18:21:49</td>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1328</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>3214</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3360</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3495</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 12:54:22</td>\n",
       "      <td>8</td>\n",
       "      <td>299</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8786</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2233</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10387</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6088</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 13:10:30</td>\n",
       "      <td>25</td>\n",
       "      <td>498</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6618</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2393</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5768</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3425</td>\n",
       "      <td>BY</td>\n",
       "      <td>2019-08-19 13:29:47</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8321</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6179</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5037</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17416</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-08-19 15:19:35</td>\n",
       "      <td>3</td>\n",
       "      <td>414</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>2950</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>2232</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7095</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1901</td>\n",
       "      <td>US</td>\n",
       "      <td>2019-08-19 15:38:29</td>\n",
       "      <td>367</td>\n",
       "      <td>336</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7163 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I    Q3E  Q4A  ...   Q91E  \\\n",
       "0       5   51  7107    3   91  2522    1   56   6180    2  ...   4609   \n",
       "1       5   39  6354    5   13  3092    1   12   5243    5  ...  10409   \n",
       "2       3   17  5397    4   35  2747    5   40   5262    3  ...   2691   \n",
       "3       5   41  3055    2   14  3348    1   13   5141    1  ...   3697   \n",
       "4       1   76  2542    2   54  1878    1   15   5637    1  ...   1662   \n",
       "...   ...  ...   ...  ...  ...   ...  ...  ...    ...  ...  ...    ...   \n",
       "7183    1   46  1328    4   82  3214    4   43   3360    5  ...   3495   \n",
       "7184    2    5  8786    5   24  2233    5   10  10387    5  ...   6088   \n",
       "7185    3   29  6618    5   44  2393    4   58   5768    5  ...   3425   \n",
       "7186    4   15  8321    2   18  6179    5   60   5037    1  ...  17416   \n",
       "7187    5   57  2950    2   66  2232    4   24   7095    4  ...   1901   \n",
       "\n",
       "      COUNTRY             DATELOAD  INTROELAPSE  TESTELAPSE  SURVEYELAPSE  \\\n",
       "0          US  2019-02-20 17:35:52            1         461            16   \n",
       "1          AU  2019-02-20 17:46:32           21         467            15   \n",
       "2          BR  2019-02-20 18:10:24           56         306            17   \n",
       "3          CZ  2019-02-20 18:16:21            2         287            14   \n",
       "4          CA  2019-02-20 18:21:49            2         325            12   \n",
       "...       ...                  ...          ...         ...           ...   \n",
       "7183       US  2019-08-19 12:54:22            8         299            14   \n",
       "7184       CA  2019-08-19 13:10:30           25         498            20   \n",
       "7185       BY  2019-08-19 13:29:47            3         326            17   \n",
       "7186       CA  2019-08-19 15:19:35            3         414            23   \n",
       "7187       US  2019-08-19 15:38:29          367         336            16   \n",
       "\n",
       "      GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0          2       1   23                    3  \n",
       "1          1       2   25                    2  \n",
       "2          1       2   19                    1  \n",
       "3          1       1   23                    1  \n",
       "4          1       1   18                    2  \n",
       "...      ...     ...  ...                  ...  \n",
       "7183       2       1   53                    1  \n",
       "7184       1       1   20                    1  \n",
       "7185       2       2   28                    1  \n",
       "7186       2       1   19                    1  \n",
       "7187       2       1   25                    1  \n",
       "\n",
       "[7163 rows x 282 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the rows that are not contributing to Classification values \"Introvert/Extrovert/Ambivert\" \n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.loc[QuestionnaireDF['INTROVERT_EXTROVERT'] != 0]\n",
    "QuestionnaireDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014b0fe3-98f4-41d6-8a66-d6a9a46f84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q90I</th>\n",
       "      <th>Q90E</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>Q91I</th>\n",
       "      <th>Q91E</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ENGNAT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>7107</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>2522</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>6180</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4648</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>4609</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>6354</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3092</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5243</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3884</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10409</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5397</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>2747</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>5262</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>3055</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3348</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5141</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2345</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>3697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>2542</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5637</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>6413</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>1662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q1I   Q1E  Q2A  Q2I   Q2E  Q3A  Q3I   Q3E  Q4A  ...  Q90A  Q90I  Q90E  \\\n",
       "0    5   51  7107    3   91  2522    1   56  6180    2  ...     3    40  4648   \n",
       "1    5   39  6354    5   13  3092    1   12  5243    5  ...     4    28  3884   \n",
       "2    3   17  5397    4   35  2747    5   40  5262    3  ...     1    87  1759   \n",
       "3    5   41  3055    2   14  3348    1   13  5141    1  ...     3    15  2345   \n",
       "4    1   76  2542    2   54  1878    1   15  5637    1  ...     5    86  6413   \n",
       "\n",
       "   Q91A  Q91I   Q91E  GENDER  ENGNAT  AGE  INTROVERT_EXTROVERT  \n",
       "0     3    35   4609       2       1   23                    3  \n",
       "1     3     1  10409       1       2   25                    2  \n",
       "2     1    19   2691       1       2   19                    1  \n",
       "3     3    23   3697       1       1   23                    1  \n",
       "4     5    69   1662       1       1   18                    2  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only features that are considered to be important for training the model\n",
    "\n",
    "QuestionnaireDF = QuestionnaireDF.drop(columns=['COUNTRY', 'DATELOAD', 'INTROELAPSE', 'TESTELAPSE', 'SURVEYELAPSE'])\n",
    "QuestionnaireDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a15c57e-f4b3-4fee-a586-0c76bf0a0e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     14,      15,      16,      17,      18,      19,      20,\n",
       "            21,      22,      23,      24,      25,      26,      27,\n",
       "            28,      29,      30,      31,      32,      33,      34,\n",
       "            35,      36,      37,      38,      39,      40,      41,\n",
       "            42,      43,      44,      45,      46,      47,      48,\n",
       "            49,      50,      51,      52,      53,      54,      55,\n",
       "            56,      57,      58,      59,      60,      61,      62,\n",
       "            63,      64,      65,      66,      67,      68,      69,\n",
       "            70,      71,      72,      73,      75,      77,      78,\n",
       "            79,      81,      90,     255,    1979,    1983,    1990,\n",
       "          1991,    1996,    1999,    2003, 8675309], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating the data in the selected features\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4128fcc0-a29f-48fc-95d7-87e417e9b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for cleaning age feature. Drop rows with age above max_age\n",
    "\n",
    "max_age = 100\n",
    "# Age: Clean up invalid rows where age is above max_age\n",
    "age_range = (QuestionnaireDF['AGE'] < max_age)\n",
    "QuestionnaireDF = QuestionnaireDF.loc[age_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b76c0a5-9a1a-486b-b342-10ea554da41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "       48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "       65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 81, 90],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF values after the age clean up\n",
    "\n",
    "QuestionnaireDF['AGE'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e89df7-0229-4166-8564-f653b9880dda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1A',\n",
       " 'Q2A',\n",
       " 'Q3A',\n",
       " 'Q4A',\n",
       " 'Q5A',\n",
       " 'Q6A',\n",
       " 'Q7A',\n",
       " 'Q8A',\n",
       " 'Q9A',\n",
       " 'Q10A',\n",
       " 'Q11A',\n",
       " 'Q12A',\n",
       " 'Q13A',\n",
       " 'Q14A',\n",
       " 'Q15A',\n",
       " 'Q16A',\n",
       " 'Q17A',\n",
       " 'Q18A',\n",
       " 'Q19A',\n",
       " 'Q20A',\n",
       " 'Q21A',\n",
       " 'Q22A',\n",
       " 'Q23A',\n",
       " 'Q24A',\n",
       " 'Q25A',\n",
       " 'Q26A',\n",
       " 'Q27A',\n",
       " 'Q28A',\n",
       " 'Q29A',\n",
       " 'Q30A',\n",
       " 'Q31A',\n",
       " 'Q32A',\n",
       " 'Q33A',\n",
       " 'Q34A',\n",
       " 'Q35A',\n",
       " 'Q36A',\n",
       " 'Q37A',\n",
       " 'Q38A',\n",
       " 'Q39A',\n",
       " 'Q40A',\n",
       " 'Q41A',\n",
       " 'Q42A',\n",
       " 'Q43A',\n",
       " 'Q44A',\n",
       " 'Q45A',\n",
       " 'Q46A',\n",
       " 'Q47A',\n",
       " 'Q48A',\n",
       " 'Q49A',\n",
       " 'Q50A',\n",
       " 'Q51A',\n",
       " 'Q52A',\n",
       " 'Q53A',\n",
       " 'Q54A',\n",
       " 'Q55A',\n",
       " 'Q56A',\n",
       " 'Q57A',\n",
       " 'Q58A',\n",
       " 'Q59A',\n",
       " 'Q60A',\n",
       " 'Q61A',\n",
       " 'Q62A',\n",
       " 'Q63A',\n",
       " 'Q64A',\n",
       " 'Q65A',\n",
       " 'Q66A',\n",
       " 'Q67A',\n",
       " 'Q68A',\n",
       " 'Q69A',\n",
       " 'Q70A',\n",
       " 'Q71A',\n",
       " 'Q72A',\n",
       " 'Q73A',\n",
       " 'Q74A',\n",
       " 'Q75A',\n",
       " 'Q76A',\n",
       " 'Q77A',\n",
       " 'Q78A',\n",
       " 'Q79A',\n",
       " 'Q80A',\n",
       " 'Q81A',\n",
       " 'Q82A',\n",
       " 'Q83A',\n",
       " 'Q84A',\n",
       " 'Q85A',\n",
       " 'Q86A',\n",
       " 'Q87A',\n",
       " 'Q88A',\n",
       " 'Q89A',\n",
       " 'Q90A',\n",
       " 'Q91A']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Selecting only the response columns from the dataframe. Ignoring the columns with Question sequence and response time.\n",
    "\n",
    "ColumnsList = QuestionnaireDF.columns.to_list()\n",
    "\n",
    "surveyResponseColumnsList = []\n",
    "for column in ColumnsList:\n",
    "    if (column[0] == 'Q' and column[-1] == 'A'):\n",
    "        surveyResponseColumnsList.append(column)\n",
    "\n",
    "surveyResponseColumnsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f546b3-2155-4435-91ea-6374a324d4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsList = []\n",
    "# for column in ColumnsList:\n",
    "#     if (column[0] == 'Q' and column[-1] == 'E'):\n",
    "#         elapsedTimeColumnsList.append(column)\n",
    "        \n",
    "# elapsedTimeColumnsList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e432a4e-0aa9-4b0e-8dbe-6ea776e5df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# elapsedTimeColumnsDF = QuestionnaireDF[['Q1E', 'Q2E', 'Q3E', 'Q4E', 'Q5E']]\n",
    "# elapsedTimeColumnsDF = QuestionnaireDF[elapsedTimeColumnsList]\n",
    "# elapsedTimeColumnsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7a3c6b-37b5-4359-8589-9f8f038677e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 Minute = 60 Seconds = 60,000 Milliseconds\n",
    "# Identify all rows that have atleast one response time more than 1 minute\n",
    "\n",
    "# elapsedTimeColumnsDF['Q1E'].loc[lambda x : x > 60000]\n",
    "# outliersDF = elapsedTimeColumnsDF[elapsedTimeColumnsDF.gt(60000).any(axis=1)]\n",
    "# outliersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276bd704-f25e-4a76-adcc-f1461996cbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outliersinSecondsDF=outliersDF/1000\n",
    "# outliersinSecondsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98be2f21-1c42-4c42-b8fa-0e00803ccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     3     2   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     2     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     3     1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     3     5   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     5   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     4     5   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     4     4   \n",
       "\n",
       "      Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0        1     4     2     5     4     3     3                    3  \n",
       "1        2     1     3     4     4     4     3                    2  \n",
       "2        5     4     5     3     2     1     1                    1  \n",
       "3        5     3     5     4     4     3     3                    1  \n",
       "4        1     3     1     2     5     5     5                    2  \n",
       "...    ...   ...   ...   ...   ...   ...   ...                  ...  \n",
       "7183     3     4     3     4     2     5     4                    1  \n",
       "7184     4     5     4     3     1     3     2                    1  \n",
       "7185     5     4     5     3     1     1     1                    1  \n",
       "7186     1     4     1     1     4     5     2                    1  \n",
       "7187     2     4     3     5     4     4     4                    1  \n",
       "\n",
       "[7153 rows x 92 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Cleansed DF for Machine Learning\n",
    "\n",
    "#Initially we thought of using Gender, English Language and Age for Predicting the personality. But later we changed our thoughts.\n",
    "CleansedDF = QuestionnaireDF[surveyResponseColumnsList].copy()\n",
    "# CleansedDF['GENDER'] = QuestionnaireDF['GENDER']\n",
    "# CleansedDF['ENGNAT'] = QuestionnaireDF['ENGNAT']\n",
    "# CleansedDF['AGE'] = QuestionnaireDF['AGE']\n",
    "CleansedDF['INTROVERT_EXTROVERT'] = QuestionnaireDF['INTROVERT_EXTROVERT']\n",
    "\n",
    "CleansedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fcd34-1cb2-45ac-8b24-51e4b677fd8a",
   "metadata": {},
   "source": [
    "## Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a6311a-54c8-48fc-8e05-1f65e5038b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "      <th>INTROVERT_EXTROVERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q83A  Q84A  Q85A  \\\n",
       "0    5    3    1    2    3    2    3    3    4     5  ...     3     2     1   \n",
       "1    5    5    1    5    2    2    5    2    1     3  ...     2     2     2   \n",
       "2    3    4    5    3    4    5    5    5    5     5  ...     5     5     5   \n",
       "3    5    2    1    1    5    5    5    4    4     2  ...     5     5     5   \n",
       "4    1    2    1    1    3    3    5    1    3     4  ...     3     1     1   \n",
       "\n",
       "   Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  INTROVERT_EXTROVERT  \n",
       "0     4     2     5     4     3     3                    3  \n",
       "1     1     3     4     4     4     3                    2  \n",
       "2     4     5     3     2     1     1                    1  \n",
       "3     3     5     4     4     3     3                    1  \n",
       "4     3     1     2     5     5     5                    2  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleansedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "154f54cd-651d-46f5-b713-4d40e4be1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>Q82A</th>\n",
       "      <th>Q83A</th>\n",
       "      <th>Q84A</th>\n",
       "      <th>Q85A</th>\n",
       "      <th>Q86A</th>\n",
       "      <th>Q87A</th>\n",
       "      <th>Q88A</th>\n",
       "      <th>Q89A</th>\n",
       "      <th>Q90A</th>\n",
       "      <th>Q91A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7185</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7153 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  Q82A  Q83A  \\\n",
       "0       5    3    1    2    3    2    3    3    4     5  ...     1     3   \n",
       "1       5    5    1    5    2    2    5    2    1     3  ...     1     2   \n",
       "2       3    4    5    3    4    5    5    5    5     5  ...     5     5   \n",
       "3       5    2    1    1    5    5    5    4    4     2  ...     5     5   \n",
       "4       1    2    1    1    3    3    5    1    3     4  ...     2     3   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
       "7183    1    4    4    5    5    4    4    4    4     4  ...     4     3   \n",
       "7184    2    5    5    5    4    4    5    5    4     3  ...     3     3   \n",
       "7185    3    5    4    5    5    5    4    5    5     5  ...     5     5   \n",
       "7186    4    2    5    1    5    1    5    4    5     1  ...     5     4   \n",
       "7187    5    2    4    4    3    2    5    5    4     5  ...     3     4   \n",
       "\n",
       "      Q84A  Q85A  Q86A  Q87A  Q88A  Q89A  Q90A  Q91A  \n",
       "0        2     1     4     2     5     4     3     3  \n",
       "1        2     2     1     3     4     4     4     3  \n",
       "2        5     5     4     5     3     2     1     1  \n",
       "3        5     5     3     5     4     4     3     3  \n",
       "4        1     1     3     1     2     5     5     5  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7183     5     3     4     3     4     2     5     4  \n",
       "7184     5     4     5     4     3     1     3     2  \n",
       "7185     5     5     4     5     3     1     1     1  \n",
       "7186     5     1     4     1     1     4     5     2  \n",
       "7187     4     2     4     3     5     4     4     4  \n",
       "\n",
       "[7153 rows x 91 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CleansedDF.drop(columns=['INTROVERT_EXTROVERT'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c8a8323-13ff-42b4-802a-51866db1382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "7183    1\n",
       "7184    1\n",
       "7185    1\n",
       "7186    1\n",
       "7187    1\n",
       "Name: INTROVERT_EXTROVERT, Length: 7153, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = CleansedDF['INTROVERT_EXTROVERT']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6ae254c-d247-4825-a62d-a8a9031e3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report, plot_roc_curve, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "246ea1e0-28dc-408f-bb53-4fe18c29e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4cd979bc-dd76-4593-933d-e1ffc53d9c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape: (4792, 91) \n",
      "X_Train Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n",
      "X_Test Shape: (2361, 91) \n",
      "X_Test Columns: Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A',\n",
      "       'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A',\n",
      "       'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A', 'Q43A', 'Q44A', 'Q45A', 'Q46A',\n",
      "       'Q47A', 'Q48A', 'Q49A', 'Q50A', 'Q51A', 'Q52A', 'Q53A', 'Q54A', 'Q55A',\n",
      "       'Q56A', 'Q57A', 'Q58A', 'Q59A', 'Q60A', 'Q61A', 'Q62A', 'Q63A', 'Q64A',\n",
      "       'Q65A', 'Q66A', 'Q67A', 'Q68A', 'Q69A', 'Q70A', 'Q71A', 'Q72A', 'Q73A',\n",
      "       'Q74A', 'Q75A', 'Q76A', 'Q77A', 'Q78A', 'Q79A', 'Q80A', 'Q81A', 'Q82A',\n",
      "       'Q83A', 'Q84A', 'Q85A', 'Q86A', 'Q87A', 'Q88A', 'Q89A', 'Q90A', 'Q91A'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_Train Shape: {X_train.shape} \\nX_Train Columns: {X_train.columns}\")\n",
    "print(f\"X_Test Shape: {X_test.shape} \\nX_Test Columns: {X_test.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a8cad-b2b8-464c-8bf3-ad534d4fad5c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0e6bc2c-fc8b-4a7b-939d-ff6a24c9addd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_uns_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d028a8e-d260-42c8-92e8-2ccd01710958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = '../saved_models/IE_Predictor_model.sav'\n",
    "pickle.dump(rf_uns_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c02c33d-4a23-4bd5-ab4e-07e1647d5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for the Random Forest Classifier model based on unscaled data\n",
    "\n",
    "# y_pred = rf_uns_classifier.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6980e60-7dc1-4903-9b6a-559d7e3b7acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate metrics and plot the matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = rf_uns_classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=rf_uns_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=rf_uns_classifier.classes_)\n",
    "# disp.plot(cmap=\"PiYG\")\n",
    "disp.plot(cmap = 'Blues')\n",
    "# disp.plot(cmap = 'viridis')\n",
    "plt.title('1:Introvert, 2:Extrovert, 3:Ambivert')\n",
    "plt.savefig(\"../images/ConfMatrix-Introvert-Extrovert-Ambivert.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0795f71-23ce-42ae-9f16-1577040e1708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72469\n"
     ]
    }
   ],
   "source": [
    "# True Introvert, True Entrovert, True Ambert\n",
    "ti, fi1, fi2, fe1, te, fe2, fa1, fa2, ta = confusion_matrix(y_test, y_pred).ravel()\n",
    "# accuracy = (tp + tn) / (tp + fp + tn + fn) \n",
    "accuracy = (ti + te +ta) / (ti + fi1 + fi2 + fe1 + te + fe2 + fa1 + fa2 + ta) \n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c210658e-89bc-47b8-ad7e-ce27a9a4eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "\n",
      "Metrics of Random Forest Classifier Model: Average=micro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.72469\n",
      "Recall = 0.72469\n",
      "F1 score = 0.72469\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the Random Forest Classifier model based on unscaled data\n",
    "print('---------------------------------------------------------')\n",
    "print('\\nMetrics of Random Forest Classifier Model: Average=micro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a4ad105-3612-4166-ba43-ce8f58ba704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=macro\n",
      "---------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.67142\n",
      "Recall = 0.61126\n",
      "F1 score = 0.63114\n",
      "---------------------------------------------------------\n",
      "Classification Report\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=macro')\n",
    "print('---------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "print('---------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('---------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5294dc5f-9d08-41e1-89f4-edc97938a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Metrics of Random Forest Classifier Model: Average=weighted\n",
      "-----------------------------------------------------------\n",
      "Accuracy = 0.72469\n",
      "Precision = 0.70263\n",
      "Recall = 0.72469\n",
      "F1 score = 0.70506\n",
      "-----------------------------------------------------------\n",
      "Classification Report\n",
      "-----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.92      0.84      1422\n",
      "           2       0.73      0.56      0.63       345\n",
      "           3       0.51      0.36      0.42       594\n",
      "\n",
      "    accuracy                           0.72      2361\n",
      "   macro avg       0.67      0.61      0.63      2361\n",
      "weighted avg       0.70      0.72      0.71      2361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Metrics of Random Forest Classifier Model: Average=weighted')\n",
    "print('-----------------------------------------------------------')\n",
    "print('Accuracy = {:.5f}'.format(accuracy_score(y_test, y_pred,)))\n",
    "print('Precision = {:.5f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Recall = {:.5f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('F1 score = {:.5f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Classification Report')\n",
    "print('-----------------------------------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03271e44-9357-4dea-aa01-48475e98cdc8",
   "metadata": {},
   "source": [
    "## Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26ffd950-d382-4c4e-b564-fbfceebb2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baf1db-5a4f-4a4a-8546-d6e65a3ce893",
   "metadata": {},
   "source": [
    "## Random Forest on Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a5897da-2990-41e8-8f7f-00730d1572be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7246929267259635\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_s_classifier = RandomForestClassifier(random_state=1, n_estimators=400).fit(X_train_scaled, y_train)\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dc684-14ed-4e8c-903f-8f9567605f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dfb0d6cb-66b1-4f52-a3db-e2bf2793c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7765025041736227\n",
      "Testing Data Score: 0.7259635747564591\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_uns_classifier = LogisticRegression(random_state=1)\n",
    "lr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b3097f58-d739-46d9-b218-dedc2888021a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Logistic Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7773372287145242\n",
      "Testing Data Score: 0.7285048708174502\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_s_classifier = LogisticRegression(random_state=1)\n",
    "lr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Logistic Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lr_s_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_s_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb867c79-6066-48da-92da-935b0dccaba1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f56d6d06-d148-44e6-98d1-7b8e3cf822a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.29771414306965005\n",
      "Testing Data Score: 0.23095512862618128\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the unscaled data and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_uns_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_uns_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9b160811-ce66-4561-a2ac-fe1ab526823e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Linear Regression - Scaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: -0.18858285304377498\n",
      "Testing Data Score: -0.2028256166826352\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear Regression model on the scaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr_s_classifier = LinearRegression()\n",
    "\n",
    "# Fitting our model with all our features in X\n",
    "lnr_s_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Linear Regression - Scaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {lnr_uns_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lnr_uns_classifier.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170b7a-8226-4edf-bd2e-0b33487d8b26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised Learning - K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f8dbd7e-42ed-475c-8ec9-a0e3489d9b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.67033886,  2.35114578, -1.26512374, ...,  1.03228332,\n",
       "         0.63587449, -0.34222261],\n",
       "       [ 8.81531214, -3.44369779, -0.09971791, ..., -0.97881237,\n",
       "        -0.07366247,  2.54547209],\n",
       "       [-7.92862339,  1.44631933, -2.16654671, ..., -0.17084509,\n",
       "         1.06431997,  0.68866211],\n",
       "       ...,\n",
       "       [-9.36834241,  0.53485199,  0.30738356, ...,  0.70024331,\n",
       "         1.83622477,  0.86123341],\n",
       "       [-1.07244271, -1.51124964, -0.27690252, ...,  0.61299481,\n",
       "         0.41431557,  2.45471555],\n",
       "       [ 2.50898927,  2.8595484 , -2.56999545, ...,  0.41781354,\n",
       "         1.12498342, -0.10712733]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal Component Analysis \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instead of providing the number of components while instantiating the PCA, by specifying the float number between 0.0 and 1.0. \n",
    "# This float value represents the ratio of variance you wish to preserve. Here I am setting the variance to 90%.\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ca7f754-dddb-4047-9327-d42135401ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21175407, 0.04118472, 0.03541609, 0.03495766, 0.02571859,\n",
       "       0.02080139, 0.01877798, 0.01775038, 0.01694538, 0.01560599,\n",
       "       0.0154238 , 0.01427474, 0.01331403, 0.01287147, 0.01227709,\n",
       "       0.0119876 , 0.01171768, 0.01141129, 0.01094775, 0.01061088,\n",
       "       0.01046132, 0.01018335, 0.00990189, 0.00973743, 0.00950975,\n",
       "       0.00924435, 0.00906215, 0.00900233, 0.00895819, 0.00873947,\n",
       "       0.00864399, 0.00857402, 0.00850207, 0.00826911, 0.00804141,\n",
       "       0.00792641, 0.00785162, 0.00770022, 0.00762184, 0.00754765,\n",
       "       0.00746835, 0.00737408, 0.00723181, 0.00711815, 0.00703964,\n",
       "       0.00697871, 0.00687284, 0.00671991, 0.00659979, 0.0065546 ,\n",
       "       0.00642628, 0.00640141, 0.00627644, 0.00622479, 0.00607961,\n",
       "       0.00601429, 0.00595228, 0.00586433, 0.00571806, 0.00568078,\n",
       "       0.00559754, 0.00550387, 0.00546274, 0.00538177, 0.00535573,\n",
       "       0.0051316 ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio indicates the proportion of the dataset's variance that lies along each principal component.\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "01aabfa4-39fb-42bb-b204-f2386d7a6f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum of explained variance: 0.9022565069504944\n",
      "Number of dimensions required: 66\n"
     ]
    }
   ],
   "source": [
    "# Even though we did not explicitly provide the number of components in PCA, its calculated to be 74 to preserve 90% of the explained variance.\n",
    "\n",
    "print(f\"\\nSum of explained variance: {np.sum(pca.explained_variance_ratio_)}\")\n",
    "print(f\"Number of dimensions required: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f4823a2-0e0d-42af-8533-540b5a208f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185901e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.998459e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.524579e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.319276e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.151570e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9.020932e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>8.914481e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8.830344e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8.763365e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>8.707602e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k       inertia\n",
       "0   1  1.185901e+06\n",
       "1   2  9.998459e+05\n",
       "2   3  9.524579e+05\n",
       "3   4  9.319276e+05\n",
       "4   5  9.151570e+05\n",
       "5   6  9.020932e+05\n",
       "6   7  8.914481e+05\n",
       "7   8  8.830344e+05\n",
       "8   9  8.763365e+05\n",
       "9  10  8.707602e+05"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best value for _k_ using the Elbow Curve based on the PCA dataset\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X_pca)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5533b8a0-e842-41b6-9a43-ea13dfa89e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow curve to identify the best number of clusters\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(k)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot for k-Means Cluster Analysis')\n",
    "plt.savefig('../Images/Elbow-plot-k-Means-Cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97824f2e-2386-413d-a8a6-8ce2e7388f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KMeans Analysis shows that there would 3 clusters of data which can be understood as three classes Introvert, Extrovert and Ambivert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6946d2f6-b51f-4b21-862b-26c98d03e7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>inertia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.314372e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.128304e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.080813e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.060278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.043501e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.030424e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.019687e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.011197e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.004741e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9.990769e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k       inertia\n",
       "0   1  1.314372e+06\n",
       "1   2  1.128304e+06\n",
       "2   3  1.080813e+06\n",
       "3   4  1.060278e+06\n",
       "4   5  1.043501e+06\n",
       "5   6  1.030424e+06\n",
       "6   7  1.019687e+06\n",
       "7   8  1.011197e+06\n",
       "8   9  1.004741e+06\n",
       "9  10  9.990769e+05"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best value for _k_ using the Elbow Curve based on the Original dataset\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8e9c515f-8ceb-43cc-b9fa-52e7c4374bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow curve to identify the best number of clusters\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(k)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow plot for k-Means Cluster Analysis')\n",
    "# plt.savefig('../Images/Elbow-plot-k-Means-Cluster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d39105-9abd-4a7e-b21a-1601b94d28ea",
   "metadata": {},
   "source": [
    "## Supervised Learning - Optimization attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c89cd8-5774-474c-98dc-e756f6cdf46b",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d74f17e8-031f-489d-aef3-1eb7233c5fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Random Forest Classifier - Unscaled Data\n",
      "----------------------------------------------\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.7238458280389666\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "# adding import dependencies here again for my reference.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=None, n_jobs=-1, max_depth=None, bootstrap=True).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=1000, max_features=\"sqrt\", n_jobs=-1, max_depth=None, min_samples_split=2, bootstrap=False).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=50, max_leaf_nodes=16, n_jobs=-1).fit(X_train, y_train)\n",
    "# rf_uns_classifier_oa = RandomForestClassifier(random_state=1, n_estimators=100, max_features=None, n_jobs=-1, max_depth=2, bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Random Forest Classifier - Unscaled Data\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(f\"Training Data Score: {rf_uns_classifier_oa.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_uns_classifier_oa.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5de4-f1d0-464f-a881-8d16bcc6b922",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "\n",
    "We have trained a few classifiers, each one mostly achieving about 70% accuracy. Utilized the voting classifier to see better predictions among them.\n",
    "\n",
    "By definition of Voting classifier, it provides a way to create a better classifier by aggregating the predictions of each classifier and predict the class that gets the most votes. This majority vote classifier is called a hard voting classifier\n",
    "\n",
    "If all classifiers are able to estimate class probabilities, then we can predict the class with the highest class probability, averaged over all the individual classifiers. This is considered to be soft voting.\n",
    "\n",
    "Clearly, we can see that Voting classifier slightly outperforms all the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d4e5e84e-b426-4c73-a940-9f90b5233a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bb518988-54c0-4ae1-be35-7d4431e734ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7259635747564591\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7221516306649725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesam\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.7263871240999576\n"
     ]
    }
   ],
   "source": [
    "#Hard Voting\n",
    "\n",
    "log_clf=LogisticRegression(random_state=1)\n",
    "rnd_clf=RandomForestClassifier(random_state=1, n_estimators=400)\n",
    "svm_clf=SVC(random_state=1, probability=True)\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr',log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "                voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "122978a8-a6f6-4229-bec7-8fdd898ffc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7285048708174502\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7251164760694621\n",
      "VotingClassifier 0.7280813214739518\n"
     ]
    }
   ],
   "source": [
    "#soft Voting\n",
    "\n",
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr',log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6681f-ba68-4034-8bd3-e28a3bc6d7a6",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d973a-01f7-42f5-a4c6-32120db72381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\n",
    "                    n_estimators = 500, max_samples=1.0, bootstrap=True, n_jobs = -1\n",
    "                        )\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "bag_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {bag_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {bag_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f134fe9-88e0-4f05-88e8-1dc3f3769117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf=BaggingClassifier(\n",
    "            DecisionTreeClassifier(),n_estimators=500,\n",
    "            bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(X_train_scaled, y_train)\n",
    "y_pred=bag_clf.predict(X_test_scaled)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(bag_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d7612-4f78-4081-9c7e-efe19fe51cf0",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d08f1d4-e61a-4234-b23d-85d07b98a74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7673205342237062\n",
      "Testing Data Score: 0.7289284201609487\n",
      "----------------------------------------------\n",
      "Training Data Score: 0.7673205342237062\n",
      "Testing Data Score: 0.7289284201609487\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators = 200, algorithm='SAMME.R', learning_rate=0.5\n",
    "                            )\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test, y_test)}\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "ada_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {ada_clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {ada_clf.score(X_test_scaled, y_test)}\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "98d0f1b2-af07-4d66-800c-8db4388d352d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.4488039706336192\n",
      "Testing Data Score: 0.2491824511301085\n",
      "Best Estimators: 128\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Loss 'squared_error' not supported. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-7fadd1a5c932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mgbrt_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbst_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgbrt_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Training Data Score: {gbrt_best.score(X_train, y_train)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m         if (self.loss not in self._SUPPORTED_LOSS\n\u001b[0;32m    238\u001b[0m                 or self.loss not in _gb_losses.LOSS_FUNCTIONS):\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss '{0:s}' not supported. \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'deviance'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Loss 'squared_error' not supported. "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=520, learning_rate=0.1, warm_start=True)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {gbrt.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {gbrt.score(X_test, y_test)}\")\n",
    "\n",
    "errors = [mean_squared_error(y_test,y_pred)\n",
    "         for y_pred in gbrt.staged_predict(X_test)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "print(f\"Best Estimators: {bst_n_estimators}\")\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, learning_rate=0.1, loss='squared_error')\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {gbrt_best.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {gbrt_best.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "397e341b-c4d4-44bb-9ed9-074c35a6e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7285048708174502\n",
      "RandomForestClassifier 0.7246929267259635\n",
      "SVC 0.7251164760694621\n",
      "AdaBoostClassifier 0.7289284201609487\n",
      "VotingClassifier 0.7280813214739518\n"
     ]
    }
   ],
   "source": [
    "voting_clf=VotingClassifier(\n",
    "                estimators=[('lr',log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('adb', ada_clf)],\n",
    "                voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,ada_clf, voting_clf):\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred=clf.predict(X_test_scaled)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78a0b6-b15e-4551-9a40-7579f02e4a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
